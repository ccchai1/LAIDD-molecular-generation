{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational AutoEncoder(VAE) 모델 설명 및 학습과 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:35:36.440899Z",
     "start_time": "2021-08-30T11:35:35.762140Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from easydict import EasyDict\n",
    "from typing import List, Tuple, Dict, Union\n",
    "\n",
    "from laiddmg import (\n",
    "  VAEConfig,\n",
    "  Tokenizer,\n",
    "  VAEModel,\n",
    "  get_rawdataset,\n",
    "  get_dataset,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T01:17:37.048161Z",
     "start_time": "2021-08-18T01:17:37.045520Z"
    }
   },
   "source": [
    "## configuration, tokenizer, model 생성\n",
    "\n",
    "* `VAEConfig` class:\n",
    "  * 모델을 구성하기 위해 필요한 정보(`hidden_dim`, `num_layers` 등)들이 담긴 class입니다.\n",
    "  * 자세한 코드는 [`laiddmg/models/vae/configuration.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/models/vae/configuration.py)에 나와 있습니다.\n",
    "* `Tokenizer` class:\n",
    "  * `str`으로 된 SMILES 데이터를 미리 정의해둔 `vocab_dict`에 맞춰 token data(`int`)로 바꿔주는 역할을 합니다.\n",
    "  * 자세한 코드는 [`laiddmg/tokenization_utils.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/tokenization_utils.py)에 나와 있습니다.\n",
    "* `VAEModel` class:\n",
    "  * 실제 모델을 만들어주는 클래스입니다.\n",
    "  * `PyTorch`에서 제공하는 표준적인 방법으로 클래스를 구성하였습니다. tutorial은 [https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html) 여기서 확인할 수 있습니다.\n",
    "  * 이 모델은 Rafael Gómez-Bombarelli, et. al., [Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules](https://pubs.acs.org/doi/10.1021/acscentsci.7b00572)을 바탕으로 작성하였습니다.\n",
    "  * 자세한 코드는 [`laiddmg/models/vae/modeling.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/models/vae/modeling.py)에 나와 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:35:37.744102Z",
     "start_time": "2021-08-30T11:35:37.682233Z"
    }
   },
   "outputs": [],
   "source": [
    "model_type = 'vae'\n",
    "config = VAEConfig()\n",
    "tokenizer = Tokenizer()\n",
    "model = VAEModel(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:35:39.779688Z",
     "start_time": "2021-08-30T11:35:39.772649Z"
    }
   },
   "outputs": [],
   "source": [
    "for k, v in config.__dict__.items():\n",
    "  print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T01:20:33.876741Z",
     "start_time": "2021-08-18T01:20:33.874348Z"
    }
   },
   "source": [
    "#### How to use tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:35:41.577068Z",
     "start_time": "2021-08-30T11:35:41.562805Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:35:41.792639Z",
     "start_time": "2021-08-30T11:35:41.786934Z"
    }
   },
   "outputs": [],
   "source": [
    "smiles = 'c1ccccc1'  # 벤젠\n",
    "tokenizer(smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T01:22:07.242192Z",
     "start_time": "2021-08-18T01:22:07.239650Z"
    }
   },
   "source": [
    "#### Print model's informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:35:44.287604Z",
     "start_time": "2021-08-30T11:35:44.282092Z"
    }
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:35:44.617501Z",
     "start_time": "2021-08-30T11:35:44.612641Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'model type: {config.model_type}')\n",
    "print(f'model device: {model.device}')\n",
    "print(f'model dtype: {model.dtype}')\n",
    "print(f'number of training parameters: {model.num_parameters()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T04:41:43.868416Z",
     "start_time": "2021-08-18T04:41:43.864883Z"
    }
   },
   "source": [
    "## Model 체크\n",
    "\n",
    "* model의 input으로는 `input_ids`와 `lengths`가 필요합니다. \n",
    "* `input_ids`는 `tokenizer`를 통해 SMILES character를 각각 token number로 바꾼 결과입니다.\n",
    "* `lengths`는 각 문장(각 SMILES 데이터)의 sequence length 정보입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:35:45.537171Z",
     "start_time": "2021-08-30T11:35:45.532126Z"
    }
   },
   "outputs": [],
   "source": [
    "smiles = 'c1ccccc1'\n",
    "inputs = tokenizer(smiles)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:35:46.149366Z",
     "start_time": "2021-08-30T11:35:46.101540Z"
    }
   },
   "outputs": [],
   "source": [
    "# outputs, z_mu, z_logvar = model(**inputs)\n",
    "outputs, z_mu, z_logvar = model(input_ids=inputs['input_ids'],\n",
    "                                lengths=inputs['lengths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:35:46.371932Z",
     "start_time": "2021-08-30T11:35:46.367348Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'outputs shape: {outputs.shape}')\n",
    "print(f'latent vector mean shape: {z_mu.shape}')\n",
    "print(f'latent vector log variance shape: {z_logvar.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE architecture\n",
    "\n",
    "<img width=\"1183\" alt=\"vae-gaussian\" src=\"https://user-images.githubusercontent.com/11681225/131422864-d5b168ba-ae6a-4bb0-bccc-c985a7b95e00.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder 살펴보기\n",
    "\n",
    "* 자세한 코드는 [`laiddmg/models/vae/modeling.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/models/vae/modeling.py)에 나와 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:36:33.529206Z",
     "start_time": "2021-08-30T11:36:33.522604Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "  def __init__(self, config: VAEConfig, embeddings: nn.Module = None):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.vocab_size = config.vocab_size\n",
    "    self.embedding_dim = config.embedding_dim\n",
    "    self.encoder_hidden_dim = config.encoder_hidden_dim\n",
    "    self.encoder_num_layers = config.encoder_num_layers\n",
    "    self.encoder_dropout = config.encoder_dropout\n",
    "    self.latent_dim = config.latent_dim\n",
    "    self.padding_value = config.padding_value\n",
    "\n",
    "    if embeddings is not None:\n",
    "      self.embeddings = embeddings\n",
    "    else:\n",
    "      self.embeddings = nn.Embedding(self.vocab_size, self.embedding_dim,\n",
    "                                     padding_idx=self.padding_value)\n",
    "\n",
    "    self.gru = nn.GRU(self.embedding_dim,\n",
    "                      self.encoder_hidden_dim,\n",
    "                      self.encoder_num_layers,\n",
    "                      batch_first=True,\n",
    "                      dropout=self.encoder_dropout if self.encoder_num_layers > 1 else 0)\n",
    "    self.fc = nn.Linear(self.encoder_hidden_dim, self.latent_dim * 2)\n",
    "\n",
    "  def forward(\n",
    "    self,\n",
    "    input_ids: torch.Tensor,  # (batch_size, seq_len)\n",
    "    lengths: torch.Tensor,  # (batch_size,)\n",
    "    **kwargs,\n",
    "  ) -> Tuple[torch.Tensor]:\n",
    "    x = self.embeddings(input_ids)  # x: (batch_size, seq_len, embedding_dim)\n",
    "    x = rnn_utils.pack_padded_sequence(\n",
    "      x,\n",
    "      lengths.cpu(),\n",
    "      batch_first=True,\n",
    "      enforce_sorted=False,\n",
    "    )\n",
    "    _, hiddens = self.gru(x, None)  # hiddens: (num_layers, batch_size, encoder_hidden_dim)\n",
    "\n",
    "    hiddens = hiddens[-1]  # hiddens: (batch_size, encoder_hidden_dim) for last layer\n",
    "\n",
    "    z_mu, z_logvar = torch.split(self.fc(hiddens), self.latent_dim, dim=-1)\n",
    "    # z_mu, z_logvar: (batch_size, latent_dim)\n",
    "\n",
    "    return z_mu, z_logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:36:33.948313Z",
     "start_time": "2021-08-30T11:36:33.932352Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(config)\n",
    "z_mu, z_logvar = encoder(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:35:49.095925Z",
     "start_time": "2021-08-30T11:35:49.091569Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'latent vector mean shape {z_mu.shape}')\n",
    "print(f'latent vector log variance shape {z_logvar.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder 살펴보기\n",
    "\n",
    "* 자세한 코드는 [`laiddmg/models/vae/modeling.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/models/vae/modeling.py)에 나와 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:36:54.571398Z",
     "start_time": "2021-08-30T11:36:54.558123Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "  def __init__(self, config: VAEConfig, embeddings: nn.Module = None):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.vocab_size = config.vocab_size\n",
    "    self.embedding_dim = config.embedding_dim\n",
    "    self.latent_dim = config.latent_dim\n",
    "    self.decoder_hidden_dim = config.decoder_hidden_dim\n",
    "    self.decoder_num_layers = config.decoder_num_layers\n",
    "    self.decoder_dropout = config.decoder_dropout\n",
    "    self.input_dim = self.embedding_dim + self.latent_dim\n",
    "    self.output_dim = config.vocab_size\n",
    "    self.padding_value = config.padding_value\n",
    "\n",
    "    if embeddings is not None:\n",
    "      self.embeddings = embeddings\n",
    "    else:\n",
    "      self.embeddings = nn.Embedding(self.vocab_size, self.embedding_dim,\n",
    "                                     padding_idx=self.padding_value)\n",
    "\n",
    "    self.gru = nn.GRU(self.input_dim,\n",
    "                      self.decoder_hidden_dim,\n",
    "                      self.decoder_num_layers,\n",
    "                      batch_first=True,\n",
    "                      dropout=self.decoder_dropout if self.decoder_num_layers > 1 else 0)\n",
    "    self.z2hidden = nn.Linear(self.latent_dim, self.decoder_hidden_dim)\n",
    "    self.fc = nn.Linear(self.decoder_hidden_dim, self.output_dim)\n",
    "\n",
    "  def forward(\n",
    "    self,\n",
    "    input_ids: torch.Tensor,  # (batch_size, seq_len)\n",
    "    lengths: torch.Tensor,  # (batch_size,)\n",
    "    z: torch.Tensor,  # (batch_size, latent_dim)\n",
    "    **kwargs,\n",
    "  ) -> Tuple[torch.Tensor]:\n",
    "    x = self.embeddings(input_ids)  # x: (batch_size, seq_len, embedding_dim)\n",
    "    hiddens = self.z2hidden(z)  # hiddens: (batch_size, decoder_hidden_dim)\n",
    "    hiddens = hiddens.unsqueeze(0).repeat(self.decoder_num_layers, 1, 1)\n",
    "    # hiddens: (num_layers, batch_size, decoder_hidden_dim)\n",
    "\n",
    "    z_ = z.unsqueeze(1).repeat(1, x.shape[1], 1)  # z: (batch_size, seq_len, latent_dim)\n",
    "    x = torch.cat((x, z_), dim=-1)  # x: (batch_size, seq_len, embedding_dim + latent_dim)\n",
    "\n",
    "    x = rnn_utils.pack_padded_sequence(\n",
    "      x,\n",
    "      lengths.cpu(),\n",
    "      batch_first=True,\n",
    "      enforce_sorted=False\n",
    "    )\n",
    "    x, _ = self.gru(x, hiddens)\n",
    "    x, _ = rnn_utils.pad_packed_sequence(\n",
    "      x,\n",
    "      batch_first=True,\n",
    "    )  # x: (batch_size, seq_len, hidden_dim)\n",
    "    outputs = self.fc(x)  # outputs: (batch_size, seq_len, vocab_size)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:36:55.008243Z",
     "start_time": "2021-08-30T11:36:54.936948Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder = Decoder(config)\n",
    "outputs = decoder(**inputs, z=torch.randn(1, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:36:55.596778Z",
     "start_time": "2021-08-30T11:36:55.592063Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'decoder outputs shape: {outputs.shape}')\n",
    "print(f'input_ids shape: {inputs[\"input_ids\"].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T05:35:48.564754Z",
     "start_time": "2021-08-20T05:35:48.558789Z"
    }
   },
   "source": [
    "### VAE model class\n",
    "\n",
    "* 자세한 코드는 [`laiddmg/models/vae/modeling.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/models/vae/modeling.py)에 나와 있습니다.\n",
    "\n",
    "\n",
    "### VAE model step by step으로 알아보기\n",
    "\n",
    "1. 인풋 데이터(`input_ids`)를 Encoder(`encoder`)에 넣는다.\n",
    "2. `z_mu`와 `z_logvar`값에 reparametrization trick을 적용하여 실제 sample된 latent vector `z`를 만든다.\n",
    "3. 인코딩된 정보 latent vector `z`와 인풋 데이터(`encoder`의 인풋과 같다)를 이용하여 Decoder(`decoder`)에 적용시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:36:58.192456Z",
     "start_time": "2021-08-30T11:36:58.182662Z"
    }
   },
   "outputs": [],
   "source": [
    "class _VAEModel(nn.Module):\n",
    "\n",
    "  def __init__(self, config: VAEConfig):\n",
    "    super(VAEModel, self).__init__()\n",
    "    self.config = config\n",
    "    self.vocab_size = config.vocab_size\n",
    "    self.embedding_dim = config.embedding_dim\n",
    "    self.latent_dim = config.latent_dim\n",
    "    self.padding_value = config.padding_value\n",
    "\n",
    "    self.embeddings = nn.Embedding(self.vocab_size, self.embedding_dim,\n",
    "                                   padding_idx=self.padding_value)\n",
    "\n",
    "    self.encoder = Encoder(self.config, self.embeddings)\n",
    "    self.decoder = Decoder(self.config, self.embeddings)\n",
    "\n",
    "  def reparameterize(self, mean, logvar):\n",
    "    epsilon = torch.rand_like(mean)\n",
    "    z = epsilon * torch.exp(logvar * .5) + mean  # mean, logvar, z: (batch_size, latent_dim)\n",
    "\n",
    "    return z\n",
    "\n",
    "  def forward(\n",
    "    self,\n",
    "    input_ids: torch.Tensor,  # (batch_size, seq_len)\n",
    "    lengths: torch.Tensor,  # (batch_size,)\n",
    "    **kwargs,\n",
    "  ) -> Tuple[torch.Tensor]:\n",
    "    z_mu, z_logvar = self.encoder(input_ids, lengths)\n",
    "    z = self.reparameterize(z_mu, z_logvar)  # z: (batch_size, latent_dim)\n",
    "    y = self.decoder(input_ids, lengths, z)  # y: (batch_size, seq_len, vocab_size)\n",
    "\n",
    "    return y, z_mu, z_logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:24:26.172053Z",
     "start_time": "2021-08-20T07:24:26.158807Z"
    }
   },
   "source": [
    "#### 1. 인풋 데이터(`input_ids`)를 Encoder(`encoder`)에 넣는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:36:59.991359Z",
     "start_time": "2021-08-30T11:36:59.972081Z"
    }
   },
   "outputs": [],
   "source": [
    "z_mu, z_logvar = model.encoder(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:00.215995Z",
     "start_time": "2021-08-30T11:37:00.212210Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'latent vector mean shape: {z_mu.shape}')\n",
    "print(f'latent vector log variance shape: {z_logvar.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. `z_mu`와 `z_logvar`값에 reparametrization trick을 적용하여 실제 sample된 latent vector `z`를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:02.151208Z",
     "start_time": "2021-08-30T11:37:02.148256Z"
    }
   },
   "outputs": [],
   "source": [
    "epsilon = torch.rand_like(z_mu)\n",
    "z = epsilon * torch.exp(z_logvar * .5) + z_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:02.355535Z",
     "start_time": "2021-08-30T11:37:02.351740Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'latent vector shape: {z.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:24:26.172053Z",
     "start_time": "2021-08-20T07:24:26.158807Z"
    }
   },
   "source": [
    "#### 3. 인코딩된 정보 latent vector `z`와 인풋 데이터(`encoder의 인풋과 같다)를 이용하여 decoder에 적용시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:03.732705Z",
     "start_time": "2021-08-30T11:37:03.682298Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model.decoder(**inputs, z=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:04.125578Z",
     "start_time": "2021-08-30T11:37:04.122239Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'outputs shape: {outputs.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T05:15:57.690026Z",
     "start_time": "2021-08-18T05:15:57.687056Z"
    }
   },
   "source": [
    "## Data 얻기\n",
    "\n",
    "* [Molecular Sets (MOSES): A benchmarking platform for molecular generation models](https://github.com/molecularsets/moses)에서 사용한 ZINC데이터를 random sampling을 통해 `train : test = 250000 : 30000`으로 나누었습니다.\n",
    "* 실제 데이터 파일 경로는 아래와 같습니다.\n",
    "  * [`datasets/moses`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/datasets/moses)\n",
    "* `get_rawdataset`함수를 이용하여 얻은 데이터는 각 항목이 SMILES `str`데이터로 이루어진 `np.ndarray`입니다.\n",
    "* 이 rawdataset을 사용하기 편하게 `custom Dataset` class를 만들었습니다.\n",
    "  * `custom Dataset`을 만드는 간단한 예제는 [PyTorch tutorial](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files)에 있습니다.\n",
    "  * 자세한 코드는 [`laiddmg/ᅟdatasets.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/datasets.py)에 나와 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:06.193224Z",
     "start_time": "2021-08-30T11:37:06.002379Z"
    }
   },
   "outputs": [],
   "source": [
    "train = get_rawdataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:06.197988Z",
     "start_time": "2021-08-30T11:37:06.194621Z"
    }
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:06.386103Z",
     "start_time": "2021-08-30T11:37:06.382678Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'number of training dataset: {len(train)}')\n",
    "print(f'raw data type: {type(train[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `model`에 sample data 적용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:08.408947Z",
     "start_time": "2021-08-30T11:37:08.401696Z"
    }
   },
   "outputs": [],
   "source": [
    "sampled_data = train[:4]\n",
    "inputs = tokenizer(sampled_data)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `inputs`를 `model`의 입력값으로 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:09.984904Z",
     "start_time": "2021-08-30T11:37:08.956622Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs, z_mu, z_logvar = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:09.989282Z",
     "start_time": "2021-08-30T11:37:09.986266Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'outputs shape: {outputs.shape}')\n",
    "print(f'latent vector mean shape: {z_mu.shape}')\n",
    "print(f'latent vector log variance shape: {z_logvar.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T05:43:51.928351Z",
     "start_time": "2021-08-18T05:43:51.924835Z"
    }
   },
   "source": [
    "### PyTorch `Dataset`, `DataLoader` 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:09.992050Z",
     "start_time": "2021-08-30T11:37:09.990274Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:09.994402Z",
     "start_time": "2021-08-30T11:37:09.992842Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(train, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:10.013066Z",
     "start_time": "2021-08-30T11:37:10.007338Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T06:53:56.747987Z",
     "start_time": "2021-08-18T06:53:56.743885Z"
    }
   },
   "source": [
    "#### `input_id`와 `target`의 관계\n",
    "\n",
    "RNN을 이용한 생성모델(generative model)은 language model의 학습방법을 이용한다.\n",
    "Language model은 간단하게 이야기하면 다음 단어를 예측하는 모델이다.\n",
    "다음 단어를 예측한다는 뜻은 RNN 그림을 보면 쉽게 이해할 수 있다.\n",
    "\n",
    "![RNN-input-target](https://user-images.githubusercontent.com/11681225/129859647-af31934a-0eea-4ad8-9a85-2d3c2a75f517.jpeg)\n",
    "\n",
    "위와 같이 input data의 token이 하나씩 이동한 것이 target이 되는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:12.906199Z",
     "start_time": "2021-08-30T11:37:12.902545Z"
    }
   },
   "outputs": [],
   "source": [
    "def _pad_sequence(data: List[torch.Tensor],\n",
    "                  padding_value: int = 0) -> torch.Tensor:\n",
    "  return rnn_utils.pad_sequence(data,\n",
    "                                batch_first=True,\n",
    "                                padding_value=padding_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:13.350004Z",
     "start_time": "2021-08-30T11:37:13.342408Z"
    }
   },
   "outputs": [],
   "source": [
    "def _collate_fn(batch: List[Dict[str, Union[torch.Tensor, str, int]]],\n",
    "                **kwargs) -> Dict[str, Union[torch.Tensor, List[str], List[int]]]:\n",
    "\n",
    "  indexes = [item['index'] for item in batch]\n",
    "  smiles = [item['smiles'] for item in batch]\n",
    "  input_ids = [item['input_id'] for item in batch]\n",
    "  targets = [item['target'] for item in batch]\n",
    "  lengths = [item['length'] for item in batch]\n",
    "\n",
    "  padding_value = tokenizer.padding_value\n",
    "  input_ids = _pad_sequence(input_ids, padding_value)\n",
    "  targets = _pad_sequence(targets, padding_value)\n",
    "  lengths = torch.LongTensor(lengths)\n",
    "\n",
    "  return {'input_ids': input_ids,\n",
    "          'targets': targets,\n",
    "          'lengths': lengths,\n",
    "          'smiles': smiles,\n",
    "          'indexes': indexes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:13.984729Z",
     "start_time": "2021-08-30T11:37:13.981792Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=4,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=_collate_fn,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T23:33:34.497465Z",
     "start_time": "2021-08-18T23:33:34.494157Z"
    }
   },
   "source": [
    "### Train without `Trainer` class\n",
    "\n",
    "* 실제 사용할 수 있게 패키징한 코드에서는 `Trainer` class를 만들어 사용하기 편리하게 모듈화 시켰습니다.\n",
    "* 하지만 해당 Jupyter notebook은 이해를 돕기위해 모듈화 되어 있는 코드를 풀어서 블록 단위로 나타내었습니다.\n",
    "* `Trainer`에 관련된 자세한 코드는 아래 링크에 있습니다.\n",
    "  * [`laiddmg/trainer.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/trainer.py)\n",
    "  * [`laiddmg/models/vae/vae_trainer.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/models/vae/vae_trainer.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loss function and optimizer 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:18.880424Z",
     "start_time": "2021-08-30T11:37:18.877125Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = EasyDict({\n",
    "  'output_dir': 'outputs/vae/jupyter1',\n",
    "  'num_train_epochs': 10,\n",
    "  'batch_size': 256,\n",
    "  'lr': 1e-3,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:19.225155Z",
     "start_time": "2021-08-30T11:37:19.222014Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=training_args.batch_size,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=_collate_fn,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:19.936386Z",
     "start_time": "2021-08-30T11:37:19.931911Z"
    }
   },
   "outputs": [],
   "source": [
    "reconstruction_loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.padding_value)\n",
    "optimizer = optim.Adam(model.parameters(), lr=training_args.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:22.312825Z",
     "start_time": "2021-08-30T11:37:22.012946Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:26.176656Z",
     "start_time": "2021-08-30T11:37:22.356732Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T04:59:44.110368Z",
     "start_time": "2021-08-23T04:59:44.107785Z"
    }
   },
   "source": [
    "### KL annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:26.452470Z",
     "start_time": "2021-08-30T11:37:26.179438Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import AnnealingSchedules\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:29.790299Z",
     "start_time": "2021-08-30T11:37:29.786902Z"
    }
   },
   "outputs": [],
   "source": [
    "kl_annealing = AnnealingSchedules(\n",
    "  method='cycle_sigmoid',  # cycle_linear, cycle_sigmoid, cycle_cosine\n",
    "  update_unit='step',  # epoch, step\n",
    "  num_training_steps=100,\n",
    "  num_training_steps_per_epoch=10,\n",
    "  start_weight=0.0,\n",
    "  stop_weight=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:30.230042Z",
     "start_time": "2021-08-30T11:37:30.227233Z"
    }
   },
   "outputs": [],
   "source": [
    "kl_annealing_weight = []\n",
    "for step in range(100):\n",
    "  kl_annealing_weight.append(kl_annealing(step)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:30.680120Z",
     "start_time": "2021-08-30T11:37:30.592092Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(kl_annealing_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:37:32.937614Z",
     "start_time": "2021-08-30T11:37:32.933446Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(epoch: int, global_step: int, model: nn.Module):\n",
    "  checkpoint_dir = os.path.join(training_args.output_dir)\n",
    "  os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "  ckpt_name = f'ckpt_{epoch:03d}.pt'\n",
    "  ckpt_path = os.path.join(checkpoint_dir, ckpt_name)\n",
    "  \n",
    "  torch.save({'epoch': epoch,\n",
    "              'global_step': global_step,\n",
    "              'model_state_dict': model.state_dict()},\n",
    "             ckpt_path)\n",
    "  print(f'saved {model.config.model_type} model at epoch {epoch}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL Divergence Loss\n",
    "\n",
    "![vae kl loss](https://user-images.githubusercontent.com/11681225/131319712-3ca94a3c-0f72-4b9b-9a37-1b91e53c608c.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:05.355634Z",
     "start_time": "2021-08-30T11:37:57.376633Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "global_step = 0\n",
    "\n",
    "kl_annealing = AnnealingSchedules(\n",
    "  method='cycle_linear',  # cycle_linear, cycle_sigmoid, cycle_cosine\n",
    "  update_unit='epoch',  # epoch, step\n",
    "  num_training_steps=len(train_dataloader) * training_args.num_train_epochs,\n",
    "  num_training_steps_per_epoch=len(train_dataloader),\n",
    "  start_weight=0.0,\n",
    "  stop_weight=0.05,\n",
    ")\n",
    "\n",
    "for epoch in range(1, training_args.num_train_epochs + 1):\n",
    "  print(f'\\nStart training: {epoch} Epoch\\n')\n",
    "  \n",
    "  for i, data in enumerate(train_dataloader, 1):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    data['input_ids'] = data['input_ids'].to(device)\n",
    "    data['targets'] = data['targets'].to(device)\n",
    "    outputs, z_mu, z_logvar = model(data['input_ids'], data['lengths'])\n",
    "    \n",
    "    reconstruction_loss = reconstruction_loss_fn(outputs.view(-1, outputs.shape[-1]),\n",
    "                                                 data['targets'].view(-1))\n",
    "    \n",
    "    kl_loss = .5 * (torch.exp(z_logvar) + z_mu**2 - 1. - z_logvar).sum(1).mean()\n",
    "    \n",
    "    kl_annealing_weight = kl_annealing(global_step)\n",
    "    \n",
    "    total_loss = reconstruction_loss + kl_annealing_weight * kl_loss\n",
    "    \n",
    "    total_loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(),\n",
    "                             max_norm=50)\n",
    "    optimizer.step()\n",
    "    global_step += 1\n",
    "    \n",
    "    if global_step % 100 == 0:\n",
    "      print(f'{epoch} Epochs | {i}/{len(train_dataloader)} | reconst_loss: {reconstruction_loss.item():.4g} | '\n",
    "            f'kl_loss: {kl_loss:.4g}, total_loss: {total_loss:.4g}, '\n",
    "            f'kl_annealing: {kl_annealing(global_step - 1):.4g} ')\n",
    "\n",
    "  save_model(epoch, global_step, model)\n",
    "  \n",
    "print('Training done!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new SMILES\n",
    "\n",
    "* model을 학습한 후에는 학습된 모델을 `load`하여 SMILES를 생성할 준비를 합니다.\n",
    "* `model.generate`함수를 이용하면 새로운 SMILES sequence를 만들수 있습니다.\n",
    "* 여기서는 generation의 각 과정을 하나씩 설명합니다.\n",
    "* 자세한 코드는 [`laiddmg/generate.py`](https://github.com/ilguyi/LAIDD-molecule-generation/blob/main/laiddmg/generate.py)에 나와 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:49:44.372607Z",
     "start_time": "2021-08-29T06:49:44.338414Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = training_args.output_dir\n",
    "model = VAEModel.from_pretrained(config, os.path.join(f'{checkpoint_dir}',\n",
    "                                                      f'ckpt_{training_args.num_train_epochs:03d}.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 본 수업에서는 시간관계상 미리 학습한 `best_model`을 다운 받아서 씁니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:34.112875Z",
     "start_time": "2021-08-30T11:38:27.853124Z"
    }
   },
   "outputs": [],
   "source": [
    "!wget 'https://www.dropbox.com/s/751pqnlgwqnqkby/vae_best.tar.gz?dl=0'\n",
    "!tar xvzf vae_best.tar.gz?dl=0\n",
    "!rm -f vae_best.tar.gz?dl=0\n",
    "!mv best_model/ outputs/vae/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:37.590985Z",
     "start_time": "2021-08-30T11:38:37.528556Z"
    }
   },
   "outputs": [],
   "source": [
    "model = VAEModel.from_pretrained(config,\n",
    "                                 os.path.join('./outputs/vae/best_model/best_model.pt'))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:40.351879Z",
     "start_time": "2021-08-30T11:38:40.348252Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size_for_generate = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:40.954145Z",
     "start_time": "2021-08-30T11:38:40.682456Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model.generate(tokenizer=tokenizer,\n",
    "                         max_length=128,\n",
    "                         num_return_sequences=batch_size_for_generate,\n",
    "                         skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:40.966093Z",
     "start_time": "2021-08-30T11:38:40.961391Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T01:23:46.853695Z",
     "start_time": "2021-08-20T01:23:46.850494Z"
    }
   },
   "source": [
    "### generation 과정 step by step으로 알아보기\n",
    "\n",
    "* step 1. `input_ids`변수에 첫 번째 token 데이터인 `<START> token` 넣기\n",
    "* step 2. prior distribution(Guassian distribution)에서 latent vector `z` 샘플링\n",
    "* step 3. latent vector `z`를 decoder의 initial state로 넣기 위해 Linear레이어 적용\n",
    "* step 4. `input_ids`데이터를 `embedding`에 넣어 embedded input 얻기\n",
    "* step 5. latent vector `z`를 (모든) input data에 concatenate\n",
    "* step 6. concatenate한 input 데이터 gru에 넣기\n",
    "* step 7. `outputs`을 `Linear`레이어를 통과시켜서 `next_token_logits`을 얻기\n",
    "* step 8. `next_token_logits`을 `softmax`를 통해 확률분포를 얻음\n",
    "* step 9. 이 확률분포를 기반한 sampling 작업을 함 (`torch.multinomial`을 이용)\n",
    "* step 10. 실제로 sampling된 값이 `next_tokens`이 되고 이게 다음 스텝의 rnn 인풋으로 쓰임 (`input_ids = next_tokens`)\n",
    "* step 11. step 2 ~ step 10과정을 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:44.953529Z",
     "start_time": "2021-08-30T11:38:44.947756Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T07:14:20.751167Z",
     "start_time": "2021-08-23T07:14:20.748749Z"
    }
   },
   "source": [
    "#### step 1. `input_ids`변수에 `<START> token` 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:45.476419Z",
     "start_time": "2021-08-30T11:38:45.472138Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_inputs = torch.full((batch_size_for_generate, 1),\n",
    "                            tokenizer.convert_token_to_id(tokenizer.start_token),\n",
    "                            dtype=torch.long,\n",
    "                            device=model.device)\n",
    "generated_sequences = initial_inputs\n",
    "input_ids = initial_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:45.652039Z",
     "start_time": "2021-08-30T11:38:45.647513Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T07:06:47.477691Z",
     "start_time": "2021-08-23T07:06:47.473449Z"
    }
   },
   "source": [
    "#### step 2. prior distribution(Guassian distribution)에서 latent vector `z` 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:45.980539Z",
     "start_time": "2021-08-30T11:38:45.976903Z"
    }
   },
   "outputs": [],
   "source": [
    "z = model.sample_gaussian_dist(batch_size_for_generate)  # z: [batch_size, latent_dim]\n",
    "z_ = z.unsqueeze(1)  # z_: [batch_size, 1, latent_dim]\n",
    "# z_: step 5에서 input과 concatenate 하기 위해 shape을 맞춰줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:46.136095Z",
     "start_time": "2021-08-30T11:38:46.132563Z"
    }
   },
   "outputs": [],
   "source": [
    "print(z.shape)\n",
    "print(z_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T07:08:32.158298Z",
     "start_time": "2021-08-23T07:08:32.153435Z"
    }
   },
   "source": [
    "#### step 3. latent vector `z`를 decoder의 initial state로 넣기 위해 Linear레이어 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:46.445527Z",
     "start_time": "2021-08-30T11:38:46.441594Z"
    }
   },
   "outputs": [],
   "source": [
    "hiddens = model.decoder.z2hidden(z)  # hiddens: [batch_size, hidden_dim]\n",
    "hiddens = hiddens.unsqueeze(0).repeat(model.config.decoder_num_layers, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:46.615648Z",
     "start_time": "2021-08-30T11:38:46.612210Z"
    }
   },
   "outputs": [],
   "source": [
    "print(hiddens.shape)  # [decoder.num_layers, batch_size, hidden_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T07:10:33.802845Z",
     "start_time": "2021-08-23T07:10:33.799144Z"
    }
   },
   "source": [
    "#### step 4. `input_ids`데이터를 `embedding`에 넣어 embedded input 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:46.945212Z",
     "start_time": "2021-08-30T11:38:46.942350Z"
    }
   },
   "outputs": [],
   "source": [
    "x = model.embeddings(input_ids)  # x: [batch_size, 1, embedding_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:47.181696Z",
     "start_time": "2021-08-30T11:38:47.177207Z"
    }
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T07:15:20.068978Z",
     "start_time": "2021-08-23T07:15:20.064783Z"
    }
   },
   "source": [
    "#### step 5. latent vector `z`를 (모든) input data에 concatenate\n",
    "\n",
    "* 매 token 마다 latent vector의 정보를 추가하여 성능을 높이기 위해서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:47.515270Z",
     "start_time": "2021-08-30T11:38:47.511911Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.cat((x, z_), dim=-1)  # x: [batch_size, 1, embedding_dim + latent_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 6. concatenate한 input 데이터 gru에 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:47.855560Z",
     "start_time": "2021-08-30T11:38:47.851942Z"
    }
   },
   "outputs": [],
   "source": [
    "x, hiddens = model.decoder.gru(x, hiddens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T07:30:43.052727Z",
     "start_time": "2021-08-23T07:30:43.050241Z"
    }
   },
   "source": [
    "#### step 7. `outputs`을 `Linear`레이어를 통과시켜서 `next_token_logits`을 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:48.186674Z",
     "start_time": "2021-08-30T11:38:48.182332Z"
    }
   },
   "outputs": [],
   "source": [
    "logits = model.decoder.fc(x)\n",
    "next_token_logits = logits.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:48.361825Z",
     "start_time": "2021-08-30T11:38:48.357422Z"
    }
   },
   "outputs": [],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:48.506411Z",
     "start_time": "2021-08-30T11:38:48.501838Z"
    }
   },
   "outputs": [],
   "source": [
    "next_token_logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T01:52:29.148625Z",
     "start_time": "2021-08-20T01:52:29.145709Z"
    }
   },
   "source": [
    "#### step 8. `next_token_logits`을 `softmax`를 통해 확률분포를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:48.869908Z",
     "start_time": "2021-08-30T11:38:48.866828Z"
    }
   },
   "outputs": [],
   "source": [
    "probabilities = F.softmax(next_token_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:49.214826Z",
     "start_time": "2021-08-30T11:38:49.207372Z"
    }
   },
   "outputs": [],
   "source": [
    "probabilities[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T01:52:29.586382Z",
     "start_time": "2021-08-20T01:52:29.581315Z"
    }
   },
   "source": [
    "#### step 9. 이 확률분포를 기반한 sampling 작업을 함 ([`torch.multinomial`](https://pytorch.org/docs/stable/generated/torch.multinomial.html?highlight=multinomial#torch.multinomial)을 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:49.871639Z",
     "start_time": "2021-08-30T11:38:49.862204Z"
    }
   },
   "outputs": [],
   "source": [
    "next_tokens = torch.multinomial(probabilities, num_samples=1)\n",
    "next_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T01:49:41.633366Z",
     "start_time": "2021-08-20T01:49:41.626309Z"
    }
   },
   "source": [
    "참고 `tokenizer.vocab`\n",
    "\n",
    "```python\n",
    "{('#', 4), ('(', 5), (')', 6), ('-', 7),\n",
    " ('1', 8), ('2', 9), ('3', 10), ('4', 11), ('5', 12), ('6', 13), ('=', 14),\n",
    " ('B', 15), ('C', 16), ('F', 17), ('H', 18), ('N', 19), ('O', 20), ('S', 21),\n",
    " ('[', 22), (']', 23), ('c', 24), ('l', 25), ('n', 26), ('o', 27), ('r', 28), ('s', 29)}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T07:36:08.564746Z",
     "start_time": "2021-08-23T07:36:08.561366Z"
    }
   },
   "source": [
    "#### step 10. 실제로 sampling된 값이 `next_tokens`이 되고 이게 다음 스텝의 rnn 인풋으로 쓰임 (`input_ids = next_tokens`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:52.510608Z",
     "start_time": "2021-08-30T11:38:52.503629Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs_ids = next_tokens\n",
    "generated_sequences = torch.cat((generated_sequences, next_tokens), dim=1)\n",
    "generated_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T02:04:21.601326Z",
     "start_time": "2021-08-20T02:04:21.598478Z"
    }
   },
   "source": [
    "#### 위의 과정을 모듈화해서 `generate`함수를 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:55.639124Z",
     "start_time": "2021-08-30T11:38:55.167476Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model.generate(tokenizer=tokenizer,\n",
    "                         max_length=128,\n",
    "                         #num_return_sequences=batch_size_for_generate,\n",
    "                         num_return_sequences=256,\n",
    "                         skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:56.681864Z",
     "start_time": "2021-08-30T11:38:56.628297Z"
    }
   },
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:57.046557Z",
     "start_time": "2021-08-30T11:38:57.016948Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mols = []\n",
    "for s in outputs:\n",
    "  try:\n",
    "    mol = Chem.MolFromSmiles(s)\n",
    "  except:\n",
    "    pass\n",
    "  if mol is not None:\n",
    "    mols.append(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:57.871409Z",
     "start_time": "2021-08-30T11:38:57.867306Z"
    }
   },
   "outputs": [],
   "source": [
    "len(mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:58.526726Z",
     "start_time": "2021-08-30T11:38:58.517659Z"
    }
   },
   "outputs": [],
   "source": [
    "mols[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:58.910300Z",
     "start_time": "2021-08-30T11:38:58.902537Z"
    }
   },
   "outputs": [],
   "source": [
    "mols[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:38:59.324041Z",
     "start_time": "2021-08-30T11:38:59.316513Z"
    }
   },
   "outputs": [],
   "source": [
    "mols[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:laiddmg] *",
   "language": "python",
   "name": "conda-env-laiddmg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
