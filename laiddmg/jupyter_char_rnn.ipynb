{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character RNN(CharRNN) 모델 설명 및 학습과 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:41:02.273417Z",
     "start_time": "2021-08-30T04:41:01.576756Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from easydict import EasyDict\n",
    "from typing import List, Tuple, Dict, Union\n",
    "\n",
    "from laiddmg import (\n",
    "  CharRNNConfig,\n",
    "  Tokenizer,\n",
    "  CharRNNModel,\n",
    "  get_rawdataset,\n",
    "  get_dataset,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T01:17:37.048161Z",
     "start_time": "2021-08-18T01:17:37.045520Z"
    }
   },
   "source": [
    "## configuration, tokenizer, model 생성\n",
    "\n",
    "* `CharRNNConfig` class:\n",
    "  * 모델을 구성하기 위해 필요한 정보(`hidden_dim`, `num_layers` 등)들이 담긴 class입니다.\n",
    "  * 자세한 코드는 [`laiddmg/models/char_rnn/configuration.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/models/char_rnn/configuration.py)에 나와 있습니다.\n",
    "* `Tokenizer` class:\n",
    "  * `str`으로 된 SMILES 데이터를 미리 정의해둔 `vocab_dict`에 맞춰 token data(`int`)로 바꿔주는 역할을 합니다.\n",
    "  * 자세한 코드는 [`laiddmg/tokenization_utils.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/tokenization_utils.py)에 나와 있습니다.\n",
    "* `CharRNNModel` class:\n",
    "  * 실제 모델을 만들어주는 클래스입니다.\n",
    "  * `PyTorch`에서 제공하는 표준적인 방법으로 클래스를 구성하였습니다. tutorial은 [https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html) 여기서 확인할 수 있습니다.\n",
    "  * 이 모델은 Marwin H. S. Segler, et. al., [Generating Focused Molecule Libraries for Drug Discovery with Recurrent Neural Networks](https://pubs.acs.org/doi/10.1021/acscentsci.7b00512)을 바탕으로 작성하였습니다.\n",
    "  * 자세한 코드는 [`laiddmg/models/char_rnn/modeling.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/models/char_rnn/modeling.py)에 나와 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:41:06.536384Z",
     "start_time": "2021-08-30T04:41:06.437120Z"
    }
   },
   "outputs": [],
   "source": [
    "model_type = 'char_rnn'\n",
    "config = CharRNNConfig()\n",
    "tokenizer = Tokenizer()\n",
    "model = CharRNNModel(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:39:51.464267Z",
     "start_time": "2021-08-29T06:39:51.458388Z"
    }
   },
   "outputs": [],
   "source": [
    "for k, v in config.__dict__.items():\n",
    "  print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T01:20:33.876741Z",
     "start_time": "2021-08-18T01:20:33.874348Z"
    }
   },
   "source": [
    "#### How to use tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:39:52.724103Z",
     "start_time": "2021-08-29T06:39:52.709519Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:39:52.868540Z",
     "start_time": "2021-08-29T06:39:52.863541Z"
    }
   },
   "outputs": [],
   "source": [
    "smiles = 'c1ccccc1'  # 벤젠\n",
    "tokenizer(smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T01:22:07.242192Z",
     "start_time": "2021-08-18T01:22:07.239650Z"
    }
   },
   "source": [
    "#### Print model's informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:39:53.813828Z",
     "start_time": "2021-08-29T06:39:53.809025Z"
    }
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:39:54.319575Z",
     "start_time": "2021-08-29T06:39:54.314478Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'model type: {config.model_type}')\n",
    "print(f'model device: {model.device}')\n",
    "print(f'model dtype: {model.dtype}')\n",
    "print(f'number of training parameters: {model.num_parameters()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Model class\n",
    "\n",
    "* 자세한 코드는 [`laiddmg/models/char_rnn/modeling.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/models/char_rnn/modeling.py)에 나와 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:39:58.361731Z",
     "start_time": "2021-08-29T06:39:58.350272Z"
    }
   },
   "outputs": [],
   "source": [
    "class _CharRNNModel(nn.Module):\n",
    "\n",
    "  def __init__(self, config: CharRNNConfig):\n",
    "    super(CharRNNModel, self).__init__()\n",
    "    self.config = config\n",
    "    self.vocab_size = config.vocab_size\n",
    "    self.embedding_dim = config.embedding_dim\n",
    "    self.hidden_dim = config.hidden_dim\n",
    "    self.num_layers = config.num_layers\n",
    "    self.dropout = config.dropout\n",
    "    self.padding_value = config.padding_value\n",
    "    self.output_dim = self.vocab_size\n",
    "\n",
    "    self.embeddings = nn.Embedding(self.vocab_size, self.embedding_dim,\n",
    "                                   padding_idx=self.padding_value)\n",
    "    self.lstm = nn.LSTM(self.embedding_dim, self.hidden_dim,\n",
    "                        self.num_layers,\n",
    "                        batch_first=True,\n",
    "                        dropout=self.dropout)\n",
    "    self.fc = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "\n",
    "  def forward(\n",
    "    self,\n",
    "    input_ids: torch.Tensor,  # (batch_size, seq_len)\n",
    "    lengths: torch.Tensor,  # (batch_size,)\n",
    "    hiddens: Tuple[torch.Tensor] = None,  # (num_layers, batch_size, hidden_dim)\n",
    "    **kwargs,\n",
    "  ) -> Tuple[torch.Tensor, Tuple[torch.Tensor]]:\n",
    "    x = self.embeddings(input_ids)  # x: (batch_size, seq_len, embedding_dim)\n",
    "    x = rnn_utils.pack_padded_sequence(\n",
    "      x,\n",
    "      lengths.cpu(),\n",
    "      batch_first=True,\n",
    "      enforce_sorted=False,\n",
    "    )\n",
    "    x, hiddens = self.lstm(x, hiddens)\n",
    "    # hiddens: (h, c); (num_layers, batch_size, hidden_dim), respectively\n",
    "    x, _ = rnn_utils.pad_packed_sequence(\n",
    "      x,\n",
    "      batch_first=True,\n",
    "    )  # x: (batch_size, seq_len, hidden_dim)\n",
    "    outputs = self.fc(x)  # outputs: (batch_size, seq_len, vocab_size)\n",
    "\n",
    "    return outputs, hiddens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pack_padded_sequence` 설명을 위한 token data\n",
    "\n",
    "다음과 같은 token data (출처: https://medium.com/huggingface/understanding-emotions-from-keras-to-pytorch-3ccb61d5a983) 가 있다고 생각해봅시다.\n",
    "총 5개의 데이터가 있고 각 문장(1개의 데이터)의 길이(한 문장의 token 갯수)는 다음과 같습니다.\n",
    "`lenghts = [6, 5, 2, 4, 1]`.\n",
    "시퀀스 길이가 서로 다르기 때문에 가장 긴 길이에 맞춰 `padding`을 해줍니다.\n",
    "![token_data](https://user-images.githubusercontent.com/11681225/129828808-e1e35cf2-1730-4e9d-b616-4426c11be1aa.png)\n",
    "\n",
    "다음과 같은 `vocab_dict`에 따라 `input_ids` tensor를 만들어줍니다.\n",
    "```python\n",
    "vocab_dict = {\n",
    "  'I': 1,  'Mom': 2,  'No': 3,  'This': 4,  'Yes': 5,  'cooking': 6,  'is': 7,  'love': 8,\n",
    "  's': 9,  'shit': 10,  'the': 11,  'too': 12,  'way': 13,  'you': 14,  '!': 15,  '`': 16,\n",
    "}\n",
    "```\n",
    "우리가 사용할 `input_ids` tensor는 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:00.254258Z",
     "start_time": "2021-08-29T06:40:00.249232Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids = torch.LongTensor([\n",
    "  [  1,   8,   2,  16,   9,   6],\n",
    "  [  1,   8,  14,  12,  15,   0],\n",
    "  [  3,  13,   0,   0,   0,   0],\n",
    "  [  4,   7,  11,  10,   0,   0],\n",
    "  [  5,   0,   0,   0,   0,   0]\n",
    "])  # input_ids: (batch_size, seq_len)\n",
    "lengths = [6, 5, 2, 4, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 사용할 embedding matrix를 눈으로 확인하기 쉽게 만들어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:01.119206Z",
     "start_time": "2021-08-29T06:40:01.114980Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = 16 + 1  # `+ 1`: 1을 더해주는 이유는 padding index(0)를 추가하기 때문입니다.\n",
    "embedding_dim = 1\n",
    "embeddings = nn.Embedding.from_pretrained(torch.arange(vocab_size, dtype=torch.float).unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:01.438971Z",
     "start_time": "2021-08-29T06:40:01.432542Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T05:48:14.629660Z",
     "start_time": "2021-08-18T05:48:14.626555Z"
    }
   },
   "source": [
    "### `pack_padded_sequence` 적용\n",
    "\n",
    "* `pack_padded_sequence`의 `PyTorch` 예제는 다음 링크에 있습니다. [https://pytorch.org/tutorials/beginner/chatbot_tutorial.html#encoder](https://pytorch.org/tutorials/beginner/chatbot_tutorial.html#encoder)\n",
    "* 함수 설명은 다음 링크에 있습니다. [https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:02.884245Z",
     "start_time": "2021-08-29T06:40:02.879749Z"
    }
   },
   "outputs": [],
   "source": [
    "x = embeddings(input_ids)  # x: (batch_size, seq_len, embedding_dim)\n",
    "packed_x = rnn_utils.pack_padded_sequence(\n",
    "  x,\n",
    "  lengths,\n",
    "  batch_first=True,\n",
    "  enforce_sorted=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:03.013097Z",
     "start_time": "2021-08-29T06:40:03.007976Z"
    }
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T04:04:39.636584Z",
     "start_time": "2021-08-18T04:04:39.631237Z"
    }
   },
   "source": [
    "참고\n",
    "```\n",
    "input_ids = torch.LongTensor([\n",
    "  [  1,   8,   2,  16,   9,   6],\n",
    "  [  1,   8,  14,  12,  15,   0],\n",
    "  [  3,  13,   0,   0,   0,   0],\n",
    "  [  4,   7,  11,  10,   0,   0],\n",
    "  [  5,   0,   0,   0,   0,   0]\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:03.661611Z",
     "start_time": "2021-08-29T06:40:03.655145Z"
    }
   },
   "outputs": [],
   "source": [
    "packed_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T04:06:24.051291Z",
     "start_time": "2021-08-18T04:06:24.045586Z"
    }
   },
   "source": [
    "참고: `pack_padded_sequence`를 수행하면 시퀀스 길이에 따라 정렬을 하고 정렬된 데이터를 `pack`을 해준다.\n",
    "```python\n",
    "input_ids = torch.LongTensor([\n",
    "  [  1,   8,   2,  16,   9,   6],\n",
    "  [  1,   8,  14,  12,  15,   0],\n",
    "  [  4,   7,  11,  10,   0,   0],  # 시퀀스 길이 순서에 따라 4번째 행이 3번째 행으로 올라감\n",
    "  [  3,  13,   0,   0,   0,   0],  # 시퀀스 길이 순서에 따라 3번째 행이 4번째 행으로 내려감\n",
    "  [  5,   0,   0,   0,   0,   0]\n",
    "])\n",
    "ᅟbatch_sizes = [5, 4, 3, 3, 2, 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T04:15:03.522340Z",
     "start_time": "2021-08-18T04:15:03.387400Z"
    }
   },
   "source": [
    "### `pack_padded_sequence` 이후의 모습\n",
    "\n",
    "![packed_sequence](https://user-images.githubusercontent.com/11681225/129835933-852b6add-2acc-493c-bfdd-7693d6cfe737.png)\n",
    "(출처: https://medium.com/huggingface/understanding-emotions-from-keras-to-pytorch-3ccb61d5a983)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 간단한 RNN 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:05.041117Z",
     "start_time": "2021-08-29T06:40:05.037420Z"
    }
   },
   "outputs": [],
   "source": [
    "rnn = nn.RNN(embedding_dim, 2,\n",
    "             batch_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T05:49:35.167399Z",
     "start_time": "2021-08-18T05:49:35.164803Z"
    }
   },
   "source": [
    "### `packed_x`와 `x` (pack 하지 않은 데이터)의 rnn 결과물 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:05.602914Z",
     "start_time": "2021-08-29T06:40:05.598453Z"
    }
   },
   "outputs": [],
   "source": [
    "rnn_x, hiddens = rnn(packed_x)\n",
    "rnn_x1, hiddens1 = rnn(x)\n",
    "# hiddens: (h, c); (num_layers, batch_size, hidden_dim), respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:05.766216Z",
     "start_time": "2021-08-29T06:40:05.761125Z"
    }
   },
   "outputs": [],
   "source": [
    "hiddens1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:06.019543Z",
     "start_time": "2021-08-29T06:40:06.012997Z"
    }
   },
   "outputs": [],
   "source": [
    "rnn_x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T04:31:47.402389Z",
     "start_time": "2021-08-18T04:31:47.399421Z"
    }
   },
   "source": [
    "#### `packed`된 데이터를 다시 원래 모습으로 바꿔주기 위해 `pad_packed_sequence`를 사용한다\n",
    "\n",
    "* `pad_packed_sequence`의 자세한 함수 설명은 다음 링크에서 확인할 수 있습니다. [https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_packed_sequence.html](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_packed_sequence.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:06.360646Z",
     "start_time": "2021-08-29T06:40:06.354426Z"
    }
   },
   "outputs": [],
   "source": [
    "rnn_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:06.865300Z",
     "start_time": "2021-08-29T06:40:06.854743Z"
    }
   },
   "outputs": [],
   "source": [
    "output_x, _ = rnn_utils.pad_packed_sequence(\n",
    "  rnn_x,\n",
    "  batch_first=True,\n",
    ")  # x: (batch_size, seq_len, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:06.962093Z",
     "start_time": "2021-08-29T06:40:06.954969Z"
    }
   },
   "outputs": [],
   "source": [
    "output_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:07.058288Z",
     "start_time": "2021-08-29T06:40:07.052898Z"
    }
   },
   "outputs": [],
   "source": [
    "hiddens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T04:41:43.868416Z",
     "start_time": "2021-08-18T04:41:43.864883Z"
    }
   },
   "source": [
    "## Model 체크\n",
    "\n",
    "* model의 input으로는 `input_ids`와 `lengths`가 필요합니다. \n",
    "* `input_ids`는 `tokenizer`를 통해 SMILES character를 각각 token number로 바꾼 결과입니다.\n",
    "* `lengths`는 각 문장(각 SMILES 데이터)의 sequence length 정보입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:07.218231Z",
     "start_time": "2021-08-29T06:40:07.212467Z"
    }
   },
   "outputs": [],
   "source": [
    "smiles = 'c1ccccc1'\n",
    "inputs = tokenizer(smiles)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:07.379145Z",
     "start_time": "2021-08-29T06:40:07.311016Z"
    }
   },
   "outputs": [],
   "source": [
    "# outputs, hiddens = model(**inputs)\n",
    "outputs, hiddens = model(input_ids=inputs['input_ids'],\n",
    "                         lengths=inputs['lengths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:07.470278Z",
     "start_time": "2021-08-29T06:40:07.466054Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'outputs shape: {outputs.shape}')\n",
    "print(f'hidden state shape: {hiddens[0].shape}')\n",
    "print(f'memory state shape: {hiddens[1].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T05:15:57.690026Z",
     "start_time": "2021-08-18T05:15:57.687056Z"
    }
   },
   "source": [
    "## Data 얻기\n",
    "\n",
    "* [Molecular Sets (MOSES): A benchmarking platform for molecular generation models](https://github.com/molecularsets/moses)에서 사용한 ZINC데이터를 random sampling을 통해 `train : test = 250000 : 30000`으로 나누었습니다.\n",
    "* 실제 데이터 파일 경로는 아래와 같습니다.\n",
    "  * [`datasets/moses`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/datasets/moses)\n",
    "* `get_rawdataset`함수를 이용하여 얻은 데이터는 각 항목이 SMILES `str`데이터로 이루어진 `np.ndarray`입니다.\n",
    "* 이 rawdataset을 사용하기 편하게 `custom Dataset` class를 만들었습니다.\n",
    "  * `custom Dataset`을 만드는 간단한 예제는 [PyTorch tutorial](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files)에 있습니다.\n",
    "  * 자세한 코드는 [`laiddmg/ᅟdatasets.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/datasets.py)에 나와 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:07.741410Z",
     "start_time": "2021-08-29T06:40:07.557656Z"
    }
   },
   "outputs": [],
   "source": [
    "train = get_rawdataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:07.747506Z",
     "start_time": "2021-08-29T06:40:07.743394Z"
    }
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:07.783581Z",
     "start_time": "2021-08-29T06:40:07.779802Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'number of training dataset: {len(train)}')\n",
    "print(f'raw data type: {type(train[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `model`에 sample data 적용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:07.935152Z",
     "start_time": "2021-08-29T06:40:07.928041Z"
    }
   },
   "outputs": [],
   "source": [
    "sampled_data = train[:4]\n",
    "inputs = tokenizer(sampled_data)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `tokenizer`를 이용해 token data를 character로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:08.054085Z",
     "start_time": "2021-08-29T06:40:08.048887Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:08.183875Z",
     "start_time": "2021-08-29T06:40:08.179254Z"
    }
   },
   "outputs": [],
   "source": [
    "sampled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `inputs`를 `model`의 입력값으로 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:09.939305Z",
     "start_time": "2021-08-29T06:40:08.324270Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs, hiddens = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:09.947569Z",
     "start_time": "2021-08-29T06:40:09.942923Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'outputs shape: {outputs.shape}')\n",
    "print(f'hidden state shape: {hiddens[0].shape}')\n",
    "print(f'memory state shape: {hiddens[1].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T05:43:51.928351Z",
     "start_time": "2021-08-18T05:43:51.924835Z"
    }
   },
   "source": [
    "### PyTorch `Dataset`, `DataLoader` 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:09.952712Z",
     "start_time": "2021-08-29T06:40:09.949895Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:09.957123Z",
     "start_time": "2021-08-29T06:40:09.954667Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(train, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:09.964348Z",
     "start_time": "2021-08-29T06:40:09.958710Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T06:53:56.747987Z",
     "start_time": "2021-08-18T06:53:56.743885Z"
    }
   },
   "source": [
    "#### `input_id`와 `target`의 관계\n",
    "\n",
    "RNN을 이용한 생성모델(generative model)은 language model의 학습방법을 이용한다.\n",
    "Language model은 간단하게 이야기하면 다음 단어를 예측하는 모델이다.\n",
    "다음 단어를 예측한다는 뜻은 RNN 그림을 보면 쉽게 이해할 수 있다.\n",
    "\n",
    "![RNN-input-target](https://user-images.githubusercontent.com/11681225/129859647-af31934a-0eea-4ad8-9a85-2d3c2a75f517.jpeg)\n",
    "\n",
    "위와 같이 input data의 token이 하나씩 이동한 것이 target이 되는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:09.969404Z",
     "start_time": "2021-08-29T06:40:09.966058Z"
    }
   },
   "outputs": [],
   "source": [
    "def _pad_sequence(data: List[torch.Tensor],\n",
    "                  padding_value: int = 0) -> torch.Tensor:\n",
    "  return rnn_utils.pad_sequence(data,\n",
    "                                batch_first=True,\n",
    "                                padding_value=padding_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:09.977292Z",
     "start_time": "2021-08-29T06:40:09.971061Z"
    }
   },
   "outputs": [],
   "source": [
    "def _collate_fn(batch: List[Dict[str, Union[torch.Tensor, str, int]]],\n",
    "                **kwargs) -> Dict[str, Union[torch.Tensor, List[str], List[int]]]:\n",
    "\n",
    "  indexes = [item['index'] for item in batch]\n",
    "  smiles = [item['smiles'] for item in batch]\n",
    "  input_ids = [item['input_id'] for item in batch]\n",
    "  targets = [item['target'] for item in batch]\n",
    "  lengths = [item['length'] for item in batch]\n",
    "\n",
    "  padding_value = tokenizer.padding_value\n",
    "  input_ids = _pad_sequence(input_ids, padding_value)\n",
    "  targets = _pad_sequence(targets, padding_value)\n",
    "  lengths = torch.LongTensor(lengths)\n",
    "\n",
    "  return {'input_ids': input_ids,\n",
    "          'targets': targets,\n",
    "          'lengths': lengths,\n",
    "          'smiles': smiles,\n",
    "          'indexes': indexes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:09.981352Z",
     "start_time": "2021-08-29T06:40:09.978997Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=4,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=_collate_fn,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `pad_sequence` 작동 방식\n",
    "\n",
    "* 한 batch내의 sequence length가 다른 데이터들의 sequence length를 가장 긴 데이터를 기준으로 `padding_value`(일반적으로 0)를 채워넣어 길이를 맞춰줍니다.(`padding 한다`라고 부릅니다.)\n",
    "* 자세한 함수 설명은 [여기](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html)에 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:09.987912Z",
     "start_time": "2021-08-29T06:40:09.982615Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids = [train_dataset[i]['input_id'] for i in range(4)]\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:09.994488Z",
     "start_time": "2021-08-29T06:40:09.989555Z"
    }
   },
   "outputs": [],
   "source": [
    "rnn_utils.pad_sequence(input_ids, batch_first=True, padding_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `train_dataloader` 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:12.257401Z",
     "start_time": "2021-08-29T06:40:12.237292Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_data = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:12.399717Z",
     "start_time": "2021-08-29T06:40:12.395824Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:12.566581Z",
     "start_time": "2021-08-29T06:40:12.561334Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_data['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:12.708655Z",
     "start_time": "2021-08-29T06:40:12.703540Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_data['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:12.858635Z",
     "start_time": "2021-08-29T06:40:12.854207Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_data['lengths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:13.019871Z",
     "start_time": "2021-08-29T06:40:13.015652Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_data['smiles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:13.203012Z",
     "start_time": "2021-08-29T06:40:13.198749Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_data['indexes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T23:33:34.497465Z",
     "start_time": "2021-08-18T23:33:34.494157Z"
    }
   },
   "source": [
    "### Train without `Trainer` class\n",
    "\n",
    "* 실제 사용할 수 있게 패키징한 코드에서는 `Trainer` class를 만들어 사용하기 편리하게 모듈화 시켰습니다.\n",
    "* 하지만 해당 Jupyter notebook은 이해를 돕기위해 모듈화 되어 있는 코드를 풀어서 블록 단위로 나타내었습니다.\n",
    "* `Trainer`에 관련된 자세한 코드는 아래 링크에 있습니다.\n",
    "  * [`laiddmg/trainer.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/trainer.py)\n",
    "  * [`laiddmg/models/char_rnn/char_rnn_trainer.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/models/char_rnn/char_rnn_trainer.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loss function and optimizer 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T02:52:36.901836Z",
     "start_time": "2021-08-30T02:52:36.897139Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = EasyDict({\n",
    "  'output_dir': 'outputs/char_rnn/jupyter1',\n",
    "  'num_train_epochs': 10,\n",
    "  'batch_size': 256,\n",
    "  'lr': 1e-3,\n",
    "  'step_size': 10,\n",
    "  'gamma': 0.5,  \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:16.574383Z",
     "start_time": "2021-08-29T06:40:16.570911Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=training_args.batch_size,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=_collate_fn,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:17.169980Z",
     "start_time": "2021-08-29T06:40:17.164923Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.padding_value)\n",
    "optimizer = optim.Adam(model.parameters(), lr=training_args.lr)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, training_args.step_size, training_args.gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for `lr_scheduler`\n",
    "\n",
    "* 학습할 때 더 빠른 수렴속도와 더 나은 정확도를 위해 learning rate를 조절하면서 학습하는 방식을 `learning rate scheduling`이라고 부릅니다.\n",
    "* PyTorch에는 다양한 scheduler들이 잘 정리되어 있습니다.\n",
    "  * [여기](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate)를 참조하면 다양한 scheduler들을 볼 수 있습니다.\n",
    "  * 이 튜토리얼에서 사용하는 `StepLR scheduler`는 다음 [링크](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html)에서 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:19.970371Z",
     "start_time": "2021-08-29T06:40:19.770519Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:20.430025Z",
     "start_time": "2021-08-29T06:40:20.423403Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_history = []\n",
    "for _ in range(50):\n",
    "  lr_history.append(lr_scheduler.get_last_lr()[0])\n",
    "  lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:22.573150Z",
     "start_time": "2021-08-29T06:40:22.481208Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(lr_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:25.848046Z",
     "start_time": "2021-08-29T06:40:25.844330Z"
    }
   },
   "outputs": [],
   "source": [
    "# 위에서 그림을 그리기 위해 `lr_scheduler`를 업데이트 했기때문에 다시 생성해줍니다.x\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, training_args.step_size, training_args.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:41:35.037165Z",
     "start_time": "2021-08-30T04:41:34.335087Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:34.109285Z",
     "start_time": "2021-08-29T06:40:30.937187Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:40:34.115505Z",
     "start_time": "2021-08-29T06:40:34.111637Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(epoch: int, global_step: int, model: nn.Module):\n",
    "  checkpoint_dir = os.path.join(training_args.output_dir)\n",
    "  os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "  ckpt_name = f'ckpt_{epoch:03d}.pt'\n",
    "  ckpt_path = os.path.join(checkpoint_dir, ckpt_name)\n",
    "  \n",
    "  torch.save({'epoch': epoch,\n",
    "              'global_step': global_step,\n",
    "              'model_state_dict': model.state_dict()},\n",
    "             ckpt_path)\n",
    "  print(f'saved {model.config.model_type} model at epoch {epoch}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:48:43.350278Z",
     "start_time": "2021-08-29T06:40:49.063570Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "global_step = 0\n",
    "\n",
    "for epoch in range(1, training_args.num_train_epochs + 1):\n",
    "  print(f'\\nStart training: {epoch} Epoch\\n')\n",
    "  \n",
    "  for i, data in enumerate(train_dataloader, 1):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    data['input_ids'] = data['input_ids'].to(device)\n",
    "    data['targets'] = data['targets'].to(device)\n",
    "    outputs, _ = model(data['input_ids'], data['lengths'])\n",
    "    \n",
    "    loss = loss_fn(outputs.view(-1, outputs.shape[-1]),\n",
    "                   data['targets'].view(-1))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    global_step += 1\n",
    "    \n",
    "    if global_step % 100 == 0:\n",
    "      print(f'{epoch} Epochs | {i}/{len(train_dataloader)} | loss: {loss.item():.4g} | '\n",
    "            f'lr: {lr_scheduler.get_last_lr()[0]:.4g}')\n",
    "    \n",
    "  lr_scheduler.step()\n",
    "  \n",
    "  save_model(epoch, global_step, model)\n",
    "  \n",
    "print('Training done!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new SMILES\n",
    "\n",
    "* model을 학습한 후에는 학습된 모델을 `load`하여 SMILES를 생성할 준비를 합니다.\n",
    "* `model.generate`함수를 이용하면 새로운 SMILES sequence를 만들수 있습니다.\n",
    "* 여기서는 generation의 각 과정을 하나씩 설명합니다.\n",
    "* 자세한 코드는 [`laiddmg/generate.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/generate.py)에 나와 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T02:53:52.548186Z",
     "start_time": "2021-08-30T02:53:49.341338Z"
    }
   },
   "outputs": [],
   "source": [
    "# checkpoint_dir = training_args.output_dir\n",
    "# model = CharRNNModel.from_pretrained(config,\n",
    "#                                      os.path.join(f'{checkpoint_dir}',\n",
    "#                                                   f'ckpt_{training_args.num_train_epochs:03d}.pt'))\n",
    "# model = model.to(device)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 본 수업에서는 시간관계상 미리 학습한 `best_model`을 다운 받아서 씁니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:47:40.590550Z",
     "start_time": "2021-08-30T04:47:32.147704Z"
    }
   },
   "outputs": [],
   "source": [
    "!wget 'https://www.dropbox.com/s/fqwpvx6nfh2ba1p/char_rnn_best.tar.gz?dl=0'\n",
    "!tar xvzf char_rnn_best.tar.gz?dl=0\n",
    "!rm -f char_rnn_best.tar.gz?dl=0\n",
    "!mv best_model/ outputs/char_rnn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:48:24.270682Z",
     "start_time": "2021-08-30T04:48:21.252646Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CharRNNModel.from_pretrained(config,\n",
    "                                     os.path.join('./outputs/char_rnn/best_model/best_model.pt'))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:48:26.480258Z",
     "start_time": "2021-08-30T04:48:26.477650Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size_for_generate = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:48:26.765576Z",
     "start_time": "2021-08-30T04:48:26.671926Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model.generate(tokenizer=tokenizer,\n",
    "                         max_length=128,\n",
    "                         num_return_sequences=batch_size_for_generate,\n",
    "                         skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:48:27.425610Z",
     "start_time": "2021-08-30T04:48:27.417480Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T01:23:46.853695Z",
     "start_time": "2021-08-20T01:23:46.850494Z"
    }
   },
   "source": [
    "### generation 과정 step by step으로 알아보기\n",
    "\n",
    "1. `input_ids`변수에 첫 번째 token 데이터인 `<START> token` 넣기\n",
    "2. `input_ids`데이터를 (embedding 후에) lstm 모듈에 넣어 `outputs`과 `hidden state`를 얻기\n",
    "3. `outputs`을 `Linear`레이어를 통과시켜서 `next_token_logits`을 얻기\n",
    "4. `next_token_logits`을 `softmax`를 통해 확률분포를 얻음\n",
    "5. 이 확률분포를 기반한 sampling 작업을 함 (`torch.multinomial`을 이용)\n",
    "6. 실제로 sampling된 값이 `next_tokens`이 되고 이게 다음 스텝의 rnn 인풋으로 쓰임 (`input_ids = next_tokens`)\n",
    "7. 2 ~ 6과정을 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T02:15:33.183458Z",
     "start_time": "2021-08-20T02:15:33.172551Z"
    }
   },
   "source": [
    "#### step 1. `input_ids`변수에 `<START> token` 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:59:36.986082Z",
     "start_time": "2021-08-29T06:59:36.972456Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_inputs = torch.full((batch_size_for_generate, 1),\n",
    "                            tokenizer.convert_token_to_id(tokenizer.start_token),\n",
    "                            dtype=torch.long,\n",
    "                            device=model.device)\n",
    "generated_sequences = initial_inputs\n",
    "input_ids = initial_inputs\n",
    "hiddens = model.reset_states(batch_size_for_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:59:37.277541Z",
     "start_time": "2021-08-29T06:59:37.272904Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:59:37.287049Z",
     "start_time": "2021-08-29T06:59:37.279207Z"
    }
   },
   "outputs": [],
   "source": [
    "hiddens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T02:15:33.225361Z",
     "start_time": "2021-08-20T02:15:33.192776Z"
    }
   },
   "source": [
    "#### step 2. `input_ids`데이터를 (embedding 후에) lstm 모듈에 넣어 `outputs`과 `hidden state`를 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:59:37.478962Z",
     "start_time": "2021-08-29T06:59:37.476442Z"
    }
   },
   "outputs": [],
   "source": [
    "x = model.embeddings(input_ids)\n",
    "x, hiddens = model.lstm(x, hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:59:37.503401Z",
     "start_time": "2021-08-29T06:59:37.499400Z"
    }
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T02:15:33.243819Z",
     "start_time": "2021-08-20T02:15:33.230683Z"
    }
   },
   "source": [
    "#### step 3. `outputs`을 `Linear`레이어를 통과시켜서 `next_token_logits`을 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:59:37.687381Z",
     "start_time": "2021-08-29T06:59:37.684832Z"
    }
   },
   "outputs": [],
   "source": [
    "logits = model.fc(x)\n",
    "next_token_logits = logits.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:59:37.792288Z",
     "start_time": "2021-08-29T06:59:37.788169Z"
    }
   },
   "outputs": [],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:59:37.808641Z",
     "start_time": "2021-08-29T06:59:37.805009Z"
    }
   },
   "outputs": [],
   "source": [
    "next_token_logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T02:15:33.257006Z",
     "start_time": "2021-08-20T02:15:33.254591Z"
    }
   },
   "source": [
    "#### step 4. `next_token_logits`을 `softmax`를 통해 확률분포를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:59:38.012787Z",
     "start_time": "2021-08-29T06:59:38.009952Z"
    }
   },
   "outputs": [],
   "source": [
    "probabilities = F.softmax(next_token_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:59:38.096026Z",
     "start_time": "2021-08-29T06:59:38.089875Z"
    }
   },
   "outputs": [],
   "source": [
    "probabilities[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T02:15:33.267899Z",
     "start_time": "2021-08-20T02:15:33.263783Z"
    }
   },
   "source": [
    "#### step 5. 이 확률분포를 기반한 sampling 작업을 함 ([`torch.multinomial`](https://pytorch.org/docs/stable/generated/torch.multinomial.html?highlight=multinomial#torch.multinomial)을 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:59:38.299402Z",
     "start_time": "2021-08-29T06:59:38.294912Z"
    }
   },
   "outputs": [],
   "source": [
    "next_tokens = torch.multinomial(probabilities, num_samples=1)\n",
    "next_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T01:49:41.633366Z",
     "start_time": "2021-08-20T01:49:41.626309Z"
    }
   },
   "source": [
    "참고 `tokenizer.vocab`\n",
    "\n",
    "```python\n",
    "{('#', 4), ('(', 5), (')', 6), ('-', 7),\n",
    " ('1', 8), ('2', 9), ('3', 10), ('4', 11), ('5', 12), ('6', 13), ('=', 14),\n",
    " ('B', 15), ('C', 16), ('F', 17), ('H', 18), ('N', 19), ('O', 20), ('S', 21),\n",
    " ('[', 22), (']', 23), ('c', 24), ('l', 25), ('n', 26), ('o', 27), ('r', 28), ('s', 29)}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T02:15:33.272783Z",
     "start_time": "2021-08-20T02:15:33.269071Z"
    }
   },
   "source": [
    "#### step 6. 실제로 sampling된 값이 `next_tokens`이 되고 이게 다음 스텝의 rnn 인풋으로 쓰임 (`input_ids = next_tokens`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:59:55.394155Z",
     "start_time": "2021-08-29T06:59:55.387802Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs_ids = next_tokens\n",
    "generated_sequences = torch.cat((generated_sequences, next_tokens), dim=1)\n",
    "generated_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T02:04:21.601326Z",
     "start_time": "2021-08-20T02:04:21.598478Z"
    }
   },
   "source": [
    "#### 위의 과정을 모듈화해서 `generate`함수를 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:48:41.399699Z",
     "start_time": "2021-08-30T04:48:41.174496Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model.generate(tokenizer=tokenizer,\n",
    "                         max_length=128,\n",
    "                         # num_return_sequences=batch_size_for_generate,\n",
    "                         num_return_sequences=128,\n",
    "                         skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:48:41.462953Z",
     "start_time": "2021-08-30T04:48:41.401356Z"
    }
   },
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:48:41.532597Z",
     "start_time": "2021-08-30T04:48:41.516620Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mols = []\n",
    "for s in outputs:\n",
    "  try:\n",
    "    mol = Chem.MolFromSmiles(s)\n",
    "  except:\n",
    "    pass\n",
    "  if mol is not None:\n",
    "    mols.append(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:48:41.690935Z",
     "start_time": "2021-08-30T04:48:41.687267Z"
    }
   },
   "outputs": [],
   "source": [
    "len(mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:48:41.860569Z",
     "start_time": "2021-08-30T04:48:41.852326Z"
    }
   },
   "outputs": [],
   "source": [
    "mols[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:48:42.004226Z",
     "start_time": "2021-08-30T04:48:41.996902Z"
    }
   },
   "outputs": [],
   "source": [
    "mols[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:48:42.205290Z",
     "start_time": "2021-08-30T04:48:42.197579Z"
    }
   },
   "outputs": [],
   "source": [
    "mols[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:laiddmg] *",
   "language": "python",
   "name": "conda-env-laiddmg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
