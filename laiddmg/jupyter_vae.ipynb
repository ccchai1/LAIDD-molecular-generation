{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational AutoEncoder(VAE) 모델 설명 및 학습과 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:25:02.978635Z",
     "start_time": "2021-08-30T11:25:02.291500Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from easydict import EasyDict\n",
    "from typing import List, Tuple, Dict, Union\n",
    "\n",
    "from laiddmg import (\n",
    "  VAEConfig,\n",
    "  Tokenizer,\n",
    "  VAEModel,\n",
    "  get_rawdataset,\n",
    "  get_dataset,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T01:17:37.048161Z",
     "start_time": "2021-08-18T01:17:37.045520Z"
    }
   },
   "source": [
    "## configuration, tokenizer, model 생성\n",
    "\n",
    "* `VAEConfig` class:\n",
    "  * 모델을 구성하기 위해 필요한 정보(`hidden_dim`, `num_layers` 등)들이 담긴 class입니다.\n",
    "  * 자세한 코드는 [`laiddmg/models/vae/configuration.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/models/vae/configuration.py)에 나와 있습니다.\n",
    "* `Tokenizer` class:\n",
    "  * `str`으로 된 SMILES 데이터를 미리 정의해둔 `vocab_dict`에 맞춰 token data(`int`)로 바꿔주는 역할을 합니다.\n",
    "  * 자세한 코드는 [`laiddmg/tokenization_utils.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/tokenization_utils.py)에 나와 있습니다.\n",
    "* `VAEModel` class:\n",
    "  * 실제 모델을 만들어주는 클래스입니다.\n",
    "  * `PyTorch`에서 제공하는 표준적인 방법으로 클래스를 구성하였습니다. tutorial은 [https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html) 여기서 확인할 수 있습니다.\n",
    "  * 이 모델은 Rafael Gómez-Bombarelli, et. al., [Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules](https://pubs.acs.org/doi/10.1021/acscentsci.7b00572)을 바탕으로 작성하였습니다.\n",
    "  * 자세한 코드는 [`laiddmg/models/vae/modeling.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/models/vae/modeling.py)에 나와 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:25:03.019750Z",
     "start_time": "2021-08-30T11:25:02.980576Z"
    }
   },
   "outputs": [],
   "source": [
    "model_type = 'vae'\n",
    "config = VAEConfig()\n",
    "tokenizer = Tokenizer()\n",
    "model = VAEModel(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:25:04.281939Z",
     "start_time": "2021-08-30T11:25:04.275765Z"
    }
   },
   "outputs": [],
   "source": [
    "for k, v in config.__dict__.items():\n",
    "  print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T01:20:33.876741Z",
     "start_time": "2021-08-18T01:20:33.874348Z"
    }
   },
   "source": [
    "#### How to use tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:31:55.028975Z",
     "start_time": "2021-08-30T09:31:55.013784Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:31:55.323769Z",
     "start_time": "2021-08-30T09:31:55.318176Z"
    }
   },
   "outputs": [],
   "source": [
    "smiles = 'c1ccccc1'  # 벤젠\n",
    "tokenizer(smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T01:22:07.242192Z",
     "start_time": "2021-08-18T01:22:07.239650Z"
    }
   },
   "source": [
    "#### Print model's informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:31:56.779353Z",
     "start_time": "2021-08-30T09:31:56.774194Z"
    }
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:31:57.303676Z",
     "start_time": "2021-08-30T09:31:57.298571Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'model type: {config.model_type}')\n",
    "print(f'model device: {model.device}')\n",
    "print(f'model dtype: {model.dtype}')\n",
    "print(f'number of training parameters: {model.num_parameters()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T04:41:43.868416Z",
     "start_time": "2021-08-18T04:41:43.864883Z"
    }
   },
   "source": [
    "## Model 체크\n",
    "\n",
    "* model의 input으로는 `input_ids`와 `lengths`가 필요합니다. \n",
    "* `input_ids`는 `tokenizer`를 통해 SMILES character를 각각 token number로 바꾼 결과입니다.\n",
    "* `lengths`는 각 문장(각 SMILES 데이터)의 sequence length 정보입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:31:57.978728Z",
     "start_time": "2021-08-30T09:31:57.973626Z"
    }
   },
   "outputs": [],
   "source": [
    "smiles = 'c1ccccc1'\n",
    "inputs = tokenizer(smiles)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:00.043089Z",
     "start_time": "2021-08-30T09:32:00.004133Z"
    }
   },
   "outputs": [],
   "source": [
    "# outputs, z_mu, z_logvar = model(**inputs)\n",
    "outputs, z_mu, z_logvar = model(input_ids=inputs['input_ids'],\n",
    "                                lengths=inputs['lengths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:00.530866Z",
     "start_time": "2021-08-30T09:32:00.527903Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'outputs shape: {outputs.shape}')\n",
    "print(f'latent vector mean shape: {z_mu.shape}')\n",
    "print(f'latent vector log variance shape: {z_logvar.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder 살펴보기\n",
    "\n",
    "* 자세한 코드는 [`laiddmg/models/vae/modeling.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/models/vae/modeling.py)에 나와 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:02.827205Z",
     "start_time": "2021-08-30T09:32:02.818332Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "  def __init__(self, config: VAEConfig, embeddings: nn.Module = None):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.vocab_size = config.vocab_size\n",
    "    self.embedding_dim = config.embedding_dim\n",
    "    self.encoder_hidden_dim = config.encoder_hidden_dim\n",
    "    self.encoder_num_layers = config.encoder_num_layers\n",
    "    self.encoder_dropout = config.encoder_dropout\n",
    "    self.latent_dim = config.latent_dim\n",
    "    self.padding_value = config.padding_value\n",
    "\n",
    "    if embeddings is not None:\n",
    "      self.embeddings = embeddings\n",
    "    else:\n",
    "      self.embeddings = nn.Embedding(self.vocab_size, self.embedding_dim,\n",
    "                                     padding_idx=self.padding_value)\n",
    "\n",
    "    self.gru = nn.GRU(self.embedding_dim,\n",
    "                      self.encoder_hidden_dim,\n",
    "                      self.encoder_num_layers,\n",
    "                      batch_first=True,\n",
    "                      dropout=self.encoder_dropout)\n",
    "    self.fc = nn.Linear(self.encoder_hidden_dim, self.latent_dim * 2)\n",
    "\n",
    "  def forward(\n",
    "    self,\n",
    "    input_ids: torch.Tensor,  # (batch_size, seq_len)\n",
    "    lengths: torch.Tensor,  # (batch_size,)\n",
    "    **kwargs,\n",
    "  ) -> Tuple[torch.Tensor]:\n",
    "    x = self.embeddings(input_ids)  # x: (batch_size, seq_len, embedding_dim)\n",
    "    x = rnn_utils.pack_padded_sequence(\n",
    "      x,\n",
    "      lengths.cpu(),\n",
    "      batch_first=True,\n",
    "      enforce_sorted=False,\n",
    "    )\n",
    "    _, hiddens = self.gru(x, None)  # hiddens: (num_layers, batch_size, encoder_hidden_dim)\n",
    "\n",
    "    hiddens = hiddens[-1]  # hiddens: (batch_size, encoder_hidden_dim) for last layer\n",
    "\n",
    "    z_mu, z_logvar = torch.split(self.fc(hiddens), self.latent_dim, dim=-1)\n",
    "    # z_mu, z_logvar: (batch_size, latent_dim)\n",
    "\n",
    "    return z_mu, z_logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:03.011572Z",
     "start_time": "2021-08-30T09:32:03.002278Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(config)\n",
    "z_mu, z_logvar = encoder(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:03.160620Z",
     "start_time": "2021-08-30T09:32:03.158149Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'latent vector mean shape {z_mu.shape}')\n",
    "print(f'latent vector log variance shape {z_logvar.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder 살펴보기\n",
    "\n",
    "* 자세한 코드는 [`laiddmg/models/vae/modeling.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/models/vae/modeling.py)에 나와 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:05.175201Z",
     "start_time": "2021-08-30T09:32:05.163440Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "  def __init__(self, config: VAEConfig, embeddings: nn.Module = None):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.vocab_size = config.vocab_size\n",
    "    self.embedding_dim = config.embedding_dim\n",
    "    self.latent_dim = config.latent_dim\n",
    "    self.decoder_hidden_dim = config.decoder_hidden_dim\n",
    "    self.decoder_num_layers = config.decoder_num_layers\n",
    "    self.decoder_dropout = config.decoder_dropout\n",
    "    self.input_dim = self.embedding_dim + self.latent_dim\n",
    "    self.output_dim = config.vocab_size\n",
    "    self.padding_value = config.padding_value\n",
    "\n",
    "    if embeddings is not None:\n",
    "      self.embeddings = embeddings\n",
    "    else:\n",
    "      self.embeddings = nn.Embedding(self.vocab_size, self.embedding_dim,\n",
    "                                     padding_idx=self.padding_value)\n",
    "\n",
    "    self.gru = nn.GRU(self.input_dim,\n",
    "                      self.decoder_hidden_dim,\n",
    "                      self.decoder_num_layers,\n",
    "                      batch_first=True,\n",
    "                      dropout=self.decoder_dropout)\n",
    "    self.z2hidden = nn.Linear(self.latent_dim, self.decoder_hidden_dim)\n",
    "    self.fc = nn.Linear(self.decoder_hidden_dim, self.output_dim)\n",
    "\n",
    "  def forward(\n",
    "    self,\n",
    "    input_ids: torch.Tensor,  # (batch_size, seq_len)\n",
    "    lengths: torch.Tensor,  # (batch_size,)\n",
    "    z: torch.Tensor,  # (batch_size, latent_dim)\n",
    "    **kwargs,\n",
    "  ) -> Tuple[torch.Tensor]:\n",
    "    x = self.embeddings(input_ids)  # x: (batch_size, seq_len, embedding_dim)\n",
    "    hiddens = self.z2hidden(z)  # hiddens: (batch_size, decoder_hidden_dim)\n",
    "    hiddens = hiddens.unsqueeze(0).repeat(self.decoder_num_layers, 1, 1)\n",
    "    # hiddens: (num_layers, batch_size, decoder_hidden_dim)\n",
    "\n",
    "    z_ = z.unsqueeze(1).repeat(1, x.shape[1], 1)  # z: (batch_size, seq_len, latent_dim)\n",
    "    x = torch.cat((x, z_), dim=-1)  # x: (batch_size, seq_len, embedding_dim + latent_dim)\n",
    "\n",
    "    x = rnn_utils.pack_padded_sequence(\n",
    "      x,\n",
    "      lengths.cpu(),\n",
    "      batch_first=True,\n",
    "      enforce_sorted=False\n",
    "    )\n",
    "    x, _ = self.gru(x, hiddens)\n",
    "    x, _ = rnn_utils.pad_packed_sequence(\n",
    "      x,\n",
    "      batch_first=True,\n",
    "    )  # x: (batch_size, seq_len, hidden_dim)\n",
    "    outputs = self.fc(x)  # outputs: (batch_size, seq_len, vocab_size)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:05.401425Z",
     "start_time": "2021-08-30T09:32:05.352596Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder = Decoder(config)\n",
    "outputs = decoder(**inputs, z=torch.randn(1, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:05.490221Z",
     "start_time": "2021-08-30T09:32:05.487846Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'decoder outputs shape: {outputs.shape}')\n",
    "print(f'input_ids shape: {inputs[\"input_ids\"].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T05:35:48.564754Z",
     "start_time": "2021-08-20T05:35:48.558789Z"
    }
   },
   "source": [
    "### VAE Model class\n",
    "\n",
    "* 자세한 코드는 [`laiddmg/models/vae/modeling.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/models/vae/modeling.py)에 나와 있습니다.\n",
    "\n",
    "\n",
    "### VAE model step by step으로 알아보기\n",
    "\n",
    "1. 인풋 데이터(`input_ids`)를 Encoder(`encoder`)에 넣는다.\n",
    "2. `z_mu`와 `z_logvar`값에 reparametrization trick을 적용하여 실제 sample된 latent vector `z`를 만든다.\n",
    "3. 인코딩된 정보 latent vector `z`와 인풋 데이터(`encoder`의 인풋과 같다)를 이용하여 Decoder(`decoder`)에 적용시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:05.807153Z",
     "start_time": "2021-08-30T09:32:05.798627Z"
    }
   },
   "outputs": [],
   "source": [
    "class _VAEModel(nn.Module):\n",
    "\n",
    "  def __init__(self, config: VAEConfig):\n",
    "    super(VAEModel, self).__init__()\n",
    "    self.config = config\n",
    "    self.vocab_size = config.vocab_size\n",
    "    self.embedding_dim = config.embedding_dim\n",
    "    self.latent_dim = config.latent_dim\n",
    "    self.padding_value = config.padding_value\n",
    "\n",
    "    self.embeddings = nn.Embedding(self.vocab_size, self.embedding_dim,\n",
    "                                   padding_idx=self.padding_value)\n",
    "\n",
    "    self.encoder = Encoder(self.config, self.embeddings)\n",
    "    self.decoder = Decoder(self.config, self.embeddings)\n",
    "\n",
    "  def reparameterize(self, mean, logvar):\n",
    "    epsilon = torch.rand_like(mean)\n",
    "    z = epsilon * torch.exp(logvar * .5) + mean  # mean, logvar, z: (batch_size, latent_dim)\n",
    "\n",
    "    return z\n",
    "\n",
    "  def forward(\n",
    "    self,\n",
    "    input_ids: torch.Tensor,  # (batch_size, seq_len)\n",
    "    lengths: torch.Tensor,  # (batch_size,)\n",
    "    **kwargs,\n",
    "  ) -> Tuple[torch.Tensor]:\n",
    "    z_mu, z_logvar = self.encoder(input_ids, lengths)\n",
    "    z = self.reparameterize(z_mu, z_logvar)  # z: (batch_size, latent_dim)\n",
    "    y = self.decoder(input_ids, lengths, z)  # y: (batch_size, seq_len, vocab_size)\n",
    "\n",
    "    return y, z_mu, z_logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:24:26.172053Z",
     "start_time": "2021-08-20T07:24:26.158807Z"
    }
   },
   "source": [
    "#### 1. 인풋 데이터(`input_ids`)를 Encoder(`encoder`)에 넣는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:06.453713Z",
     "start_time": "2021-08-30T09:32:06.447993Z"
    }
   },
   "outputs": [],
   "source": [
    "z_mu, z_logvar = model.encoder(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:06.524967Z",
     "start_time": "2021-08-30T09:32:06.522843Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'latent vector mean shape: {z_mu.shape}')\n",
    "print(f'latent vector log variance shape: {z_logvar.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. `z_mu`와 `z_logvar`값에 reparametrization trick을 적용하여 실제 sample된 latent vector `z`를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:06.615287Z",
     "start_time": "2021-08-30T09:32:06.613104Z"
    }
   },
   "outputs": [],
   "source": [
    "epsilon = torch.rand_like(z_mu)\n",
    "z = epsilon * torch.exp(z_logvar * .5) + z_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:06.670684Z",
     "start_time": "2021-08-30T09:32:06.668046Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'latent vector shape: {z.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T07:24:26.172053Z",
     "start_time": "2021-08-20T07:24:26.158807Z"
    }
   },
   "source": [
    "#### 3. 인코딩된 정보 latent vector `z`와 인풋 데이터(`encoder의 인풋과 같다)를 이용하여 decoder에 적용시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:07.256834Z",
     "start_time": "2021-08-30T09:32:07.242923Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model.decoder(**inputs, z=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:07.391014Z",
     "start_time": "2021-08-30T09:32:07.388411Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'outputs shape: {outputs.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T05:15:57.690026Z",
     "start_time": "2021-08-18T05:15:57.687056Z"
    }
   },
   "source": [
    "## Data 얻기\n",
    "\n",
    "* [Molecular Sets (MOSES): A benchmarking platform for molecular generation models](https://github.com/molecularsets/moses)에서 사용한 ZINC데이터를 random sampling을 통해 `train : test = 250000 : 30000`으로 나누었습니다.\n",
    "* 실제 데이터 파일 경로는 아래와 같습니다.\n",
    "  * [`datasets/moses`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/datasets/moses)\n",
    "* `get_rawdataset`함수를 이용하여 얻은 데이터는 각 항목이 SMILES `str`데이터로 이루어진 `np.ndarray`입니다.\n",
    "* 이 rawdataset을 사용하기 편하게 `custom Dataset` class를 만들었습니다.\n",
    "  * `custom Dataset`을 만드는 간단한 예제는 [PyTorch tutorial](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files)에 있습니다.\n",
    "  * 자세한 코드는 [`laiddmg/ᅟdatasets.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/datasets.py)에 나와 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:07.872872Z",
     "start_time": "2021-08-30T09:32:07.683535Z"
    }
   },
   "outputs": [],
   "source": [
    "train = get_rawdataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:07.877161Z",
     "start_time": "2021-08-30T09:32:07.874011Z"
    }
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:07.956153Z",
     "start_time": "2021-08-30T09:32:07.953033Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'number of training dataset: {len(train)}')\n",
    "print(f'raw data type: {type(train[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `model`에 sample data 적용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:08.254970Z",
     "start_time": "2021-08-30T09:32:08.248531Z"
    }
   },
   "outputs": [],
   "source": [
    "sampled_data = train[:4]\n",
    "inputs = tokenizer(sampled_data)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `inputs`를 `model`의 입력값으로 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:12.155576Z",
     "start_time": "2021-08-30T09:32:10.838553Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs, z_mu, z_logvar = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:12.163678Z",
     "start_time": "2021-08-30T09:32:12.158718Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'outputs shape: {outputs.shape}')\n",
    "print(f'latent vector mean shape: {z_mu.shape}')\n",
    "print(f'latent vector log variance shape: {z_logvar.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T05:43:51.928351Z",
     "start_time": "2021-08-18T05:43:51.924835Z"
    }
   },
   "source": [
    "### PyTorch `Dataset`, `DataLoader` 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:12.168120Z",
     "start_time": "2021-08-30T09:32:12.165341Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:12.172296Z",
     "start_time": "2021-08-30T09:32:12.169860Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(train, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:12.180091Z",
     "start_time": "2021-08-30T09:32:12.173992Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T06:53:56.747987Z",
     "start_time": "2021-08-18T06:53:56.743885Z"
    }
   },
   "source": [
    "#### `input_id`와 `target`의 관계\n",
    "\n",
    "RNN을 이용한 생성모델(generative model)은 language model의 학습방법을 이용한다.\n",
    "Language model은 간단하게 이야기하면 다음 단어를 예측하는 모델이다.\n",
    "다음 단어를 예측한다는 뜻은 RNN 그림을 보면 쉽게 이해할 수 있다.\n",
    "\n",
    "![RNN-input-target](https://user-images.githubusercontent.com/11681225/129859647-af31934a-0eea-4ad8-9a85-2d3c2a75f517.jpeg)\n",
    "\n",
    "위와 같이 input data의 token이 하나씩 이동한 것이 target이 되는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:14.227082Z",
     "start_time": "2021-08-30T09:32:14.222932Z"
    }
   },
   "outputs": [],
   "source": [
    "def _pad_sequence(data: List[torch.Tensor],\n",
    "                  padding_value: int = 0) -> torch.Tensor:\n",
    "  return rnn_utils.pad_sequence(data,\n",
    "                                batch_first=True,\n",
    "                                padding_value=padding_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:14.386665Z",
     "start_time": "2021-08-30T09:32:14.378344Z"
    }
   },
   "outputs": [],
   "source": [
    "def _collate_fn(batch: List[Dict[str, Union[torch.Tensor, str, int]]],\n",
    "                **kwargs) -> Dict[str, Union[torch.Tensor, List[str], List[int]]]:\n",
    "\n",
    "  indexes = [item['index'] for item in batch]\n",
    "  smiles = [item['smiles'] for item in batch]\n",
    "  input_ids = [item['input_id'] for item in batch]\n",
    "  targets = [item['target'] for item in batch]\n",
    "  lengths = [item['length'] for item in batch]\n",
    "\n",
    "  padding_value = tokenizer.padding_value\n",
    "  input_ids = _pad_sequence(input_ids, padding_value)\n",
    "  targets = _pad_sequence(targets, padding_value)\n",
    "  lengths = torch.LongTensor(lengths)\n",
    "\n",
    "  return {'input_ids': input_ids,\n",
    "          'targets': targets,\n",
    "          'lengths': lengths,\n",
    "          'smiles': smiles,\n",
    "          'indexes': indexes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:14.551181Z",
     "start_time": "2021-08-30T09:32:14.548538Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=4,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=_collate_fn,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T23:33:34.497465Z",
     "start_time": "2021-08-18T23:33:34.494157Z"
    }
   },
   "source": [
    "### Train without `Trainer` class\n",
    "\n",
    "* 실제 사용할 수 있게 패키징한 코드에서는 `Trainer` class를 만들어 사용하기 편리하게 모듈화 시켰습니다.\n",
    "* 하지만 해당 Jupyter notebook은 이해를 돕기위해 모듈화 되어 있는 코드를 풀어서 블록 단위로 나타내었습니다.\n",
    "* `Trainer`에 관련된 자세한 코드는 아래 링크에 있습니다.\n",
    "  * [`laiddmg/trainer.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/trainer.py)\n",
    "  * [`laiddmg/models/vae/vae_trainer.py`](https://github.com/ilguyi/LAIDD-molecular-generation/blob/main/laiddmg/models/vae/vae_trainer.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loss function and optimizer 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:17.156300Z",
     "start_time": "2021-08-30T09:32:17.152860Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = EasyDict({\n",
    "  'output_dir': 'outputs/vae/jupyter1',\n",
    "  'num_train_epochs': 10,\n",
    "  'batch_size': 256,\n",
    "  'lr': 1e-3,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:17.481661Z",
     "start_time": "2021-08-30T09:32:17.478283Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=training_args.batch_size,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=_collate_fn,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:17.982565Z",
     "start_time": "2021-08-30T09:32:17.978341Z"
    }
   },
   "outputs": [],
   "source": [
    "reconstruction_loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.padding_value)\n",
    "optimizer = optim.Adam(model.parameters(), lr=training_args.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:25:11.871353Z",
     "start_time": "2021-08-30T11:25:10.746937Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:32:23.398393Z",
     "start_time": "2021-08-30T09:32:20.342957Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T04:59:44.110368Z",
     "start_time": "2021-08-23T04:59:44.107785Z"
    }
   },
   "source": [
    "### KL annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:33:53.250834Z",
     "start_time": "2021-08-30T09:33:53.049315Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import AnnealingSchedules\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:34:31.939689Z",
     "start_time": "2021-08-30T09:34:31.934836Z"
    }
   },
   "outputs": [],
   "source": [
    "kl_annealing = AnnealingSchedules(\n",
    "  method='cycle_sigmoid',  # cycle_linear, cycle_sigmoid, cycle_cosine\n",
    "  update_unit='step',  # epoch, step\n",
    "  num_training_steps=100,\n",
    "  num_training_steps_per_epoch=10,\n",
    "  start_weight=0.0,\n",
    "  stop_weight=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:34:35.286801Z",
     "start_time": "2021-08-30T09:34:35.282890Z"
    }
   },
   "outputs": [],
   "source": [
    "kl_annealing_weight = []\n",
    "for step in range(100):\n",
    "  kl_annealing_weight.append(kl_annealing(step)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:34:35.565856Z",
     "start_time": "2021-08-30T09:34:35.473568Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(kl_annealing_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T09:34:43.329951Z",
     "start_time": "2021-08-30T09:34:43.324135Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(epoch: int, global_step: int, model: nn.Module):\n",
    "  checkpoint_dir = os.path.join(training_args.output_dir)\n",
    "  os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "  ckpt_name = f'ckpt_{epoch:03d}.pt'\n",
    "  ckpt_path = os.path.join(checkpoint_dir, ckpt_name)\n",
    "  \n",
    "  torch.save({'epoch': epoch,\n",
    "              'global_step': global_step,\n",
    "              'model_state_dict': model.state_dict()},\n",
    "             ckpt_path)\n",
    "  print(f'saved {model.config.model_type} model at epoch {epoch}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL Divergence Loss\n",
    "\n",
    "![vae kl loss](https://user-images.githubusercontent.com/11681225/131319712-3ca94a3c-0f72-4b9b-9a37-1b91e53c608c.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:49:44.337207Z",
     "start_time": "2021-08-29T06:42:40.092737Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "global_step = 0\n",
    "\n",
    "kl_annealing = AnnealingSchedules(\n",
    "  method='cycle_linear',  # cycle_linear, cycle_sigmoid, cycle_cosine\n",
    "  update_unit='epoch',  # epoch, step\n",
    "  num_training_steps=len(train_dataloader) * training_args.num_train_epochs,\n",
    "  num_training_steps_per_epoch=len(train_dataloader),\n",
    "  start_weight=0.0,\n",
    "  stop_weight=0.05,\n",
    ")\n",
    "\n",
    "for epoch in range(1, training_args.num_train_epochs + 1):\n",
    "  print(f'\\nStart training: {epoch} Epoch\\n')\n",
    "  \n",
    "  for i, data in enumerate(train_dataloader, 1):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    data['input_ids'] = data['input_ids'].to(device)\n",
    "    data['targets'] = data['targets'].to(device)\n",
    "    outputs, z_mu, z_logvar = model(data['input_ids'], data['lengths'])\n",
    "    \n",
    "    reconstruction_loss = reconstruction_loss_fn(outputs.view(-1, outputs.shape[-1]),\n",
    "                                                 data['targets'].view(-1))\n",
    "    \n",
    "    kl_loss = .5 * (torch.exp(z_logvar) + z_mu**2 - 1. - z_logvar).sum(1).mean()\n",
    "    \n",
    "    kl_annealing_weight = kl_annealing(global_step)\n",
    "    \n",
    "    total_loss = reconstruction_loss + kl_annealing_weight * kl_loss\n",
    "    \n",
    "    total_loss.backward()\n",
    "    nn.utils.clip_grad_norm_(self.model.parameters(),\n",
    "                             max_norm=50)\n",
    "    optimizer.step()\n",
    "    global_step += 1\n",
    "    \n",
    "    if global_step % 100 == 0:\n",
    "      print(f'{epoch} Epochs | {i}/{len(train_dataloader)} | reconst_loss: {reconstruction_loss.item():.4g} | '\n",
    "            f'kl_loss: {kl_loss:.4g}, total_loss: {total_loss:.4g}, '\n",
    "            f'kl_annealing: {kl_annealing(global_step - 1):.4g} ')\n",
    "\n",
    "  save_model(epoch, global_step, model)\n",
    "  \n",
    "print('Training done!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new SMILES\n",
    "\n",
    "* model을 학습한 후에는 학습된 모델을 `load`하여 SMILES를 생성할 준비를 합니다.\n",
    "* `model.generate`함수를 이용하면 새로운 SMILES sequence를 만들수 있습니다.\n",
    "* 여기서는 generation의 각 과정을 하나씩 설명합니다.\n",
    "* 자세한 코드는 [`laiddmg/generate.py`](https://github.com/ilguyi/LAIDD-molecule-generation/blob/main/laiddmg/generate.py)에 나와 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:49:44.372607Z",
     "start_time": "2021-08-29T06:49:44.338414Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = training_args.output_dir\n",
    "model = VAEModel.from_pretrained(config, os.path.join(f'{checkpoint_dir}',\n",
    "                                                      f'ckpt_{training_args.num_train_epochs:03d}.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 본 수업에서는 시간관계상 미리 학습한 `best_model`을 다운 받아서 씁니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget 'https://www.dropbox.com/s/751pqnlgwqnqkby/vae_best.tar.gz?dl=0'\n",
    "!tar xvzf vae_best.tar.gz?dl=0\n",
    "!rm -f vae_best.tar.gz?dl=0\n",
    "!mv best_model/ outputs/vae/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T10:29:35.950078Z",
     "start_time": "2021-08-30T10:29:32.142830Z"
    }
   },
   "outputs": [],
   "source": [
    "model = VAEModel.from_pretrained(config,\n",
    "                                 os.path.join('./outputs/vae/best_model/best_model.pt'))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:49:44.376269Z",
     "start_time": "2021-08-29T06:49:44.374326Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size_for_generate = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:49:47.899452Z",
     "start_time": "2021-08-29T06:49:44.377306Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model.generate(tokenizer=tokenizer,\n",
    "                         max_length=128,\n",
    "                         num_return_sequences=batch_size_for_generate,\n",
    "                         skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:49:47.903649Z",
     "start_time": "2021-08-29T06:49:47.900756Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T01:23:46.853695Z",
     "start_time": "2021-08-20T01:23:46.850494Z"
    }
   },
   "source": [
    "### generation 과정 step by step으로 알아보기\n",
    "\n",
    "* step 1. `input_ids`변수에 첫 번째 token 데이터인 `<START> token` 넣기\n",
    "* step 2. prior distribution(Guassian distribution)에서 latent vector `z` 샘플링\n",
    "* step 3. latent vector `z`를 decoder의 initial state로 넣기 위해 Linear레이어 적용\n",
    "* step 4. `input_ids`데이터를 `embedding`에 넣어 embedded input 얻기\n",
    "* step 5. latent vector `z`를 (모든) input data에 concatenate\n",
    "* step 6. concatenate한 input 데이터 gru에 넣기\n",
    "* step 7. `outputs`을 `Linear`레이어를 통과시켜서 `next_token_logits`을 얻기\n",
    "* step 8. `next_token_logits`을 `softmax`를 통해 확률분포를 얻음\n",
    "* step 9. 이 확률분포를 기반한 sampling 작업을 함 (`torch.multinomial`을 이용)\n",
    "* step 10. 실제로 sampling된 값이 `next_tokens`이 되고 이게 다음 스텝의 rnn 인풋으로 쓰임 (`input_ids = next_tokens`)\n",
    "* step 11. step 2 ~ step 10과정을 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:49:47.911467Z",
     "start_time": "2021-08-29T06:49:47.904571Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T07:14:20.751167Z",
     "start_time": "2021-08-23T07:14:20.748749Z"
    }
   },
   "source": [
    "#### step 1. `input_ids`변수에 `<START> token` 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:54:45.696152Z",
     "start_time": "2021-08-29T06:54:45.692192Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_inputs = torch.full((batch_size_for_generate, 1),\n",
    "                            tokenizer.convert_token_to_id(tokenizer.start_token),\n",
    "                            dtype=torch.long,\n",
    "                            device=model.device)\n",
    "generated_sequences = initial_inputs\n",
    "input_ids = initial_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:54:46.517292Z",
     "start_time": "2021-08-29T06:54:46.512017Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T07:06:47.477691Z",
     "start_time": "2021-08-23T07:06:47.473449Z"
    }
   },
   "source": [
    "#### step 2. prior distribution(Guassian distribution)에서 latent vector `z` 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:54:47.594862Z",
     "start_time": "2021-08-29T06:54:47.590858Z"
    }
   },
   "outputs": [],
   "source": [
    "z = model.sample_gaussian_dist(batch_size_for_generate)  # z: [batch_size, latent_dim]\n",
    "z_ = z.unsqueeze(1)  # z_: [batch_size, 1, latent_dim]\n",
    "# z_: step 5에서 input과 concatenate 하기 위해 shape을 맞춰줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:54:47.749314Z",
     "start_time": "2021-08-29T06:54:47.745979Z"
    }
   },
   "outputs": [],
   "source": [
    "print(z.shape)\n",
    "print(z_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T07:08:32.158298Z",
     "start_time": "2021-08-23T07:08:32.153435Z"
    }
   },
   "source": [
    "#### step 3. latent vector `z`를 decoder의 initial state로 넣기 위해 Linear레이어 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:54:47.877480Z",
     "start_time": "2021-08-29T06:54:47.873926Z"
    }
   },
   "outputs": [],
   "source": [
    "hiddens = model.decoder.z2hidden(z)  # hiddens: [batch_size, hidden_dim]\n",
    "hiddens = hiddens.unsqueeze(0).repeat(model.config.decoder_num_layers, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:54:47.993452Z",
     "start_time": "2021-08-29T06:54:47.989990Z"
    }
   },
   "outputs": [],
   "source": [
    "print(hiddens.shape)  # [decoder.num_layers, batch_size, hidden_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T07:10:33.802845Z",
     "start_time": "2021-08-23T07:10:33.799144Z"
    }
   },
   "source": [
    "#### step 4. `input_ids`데이터를 `embedding`에 넣어 embedded input 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:54:48.159220Z",
     "start_time": "2021-08-29T06:54:48.156188Z"
    }
   },
   "outputs": [],
   "source": [
    "x = model.embeddings(input_ids)  # x: [batch_size, 1, embedding_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:54:48.294592Z",
     "start_time": "2021-08-29T06:54:48.290061Z"
    }
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T07:15:20.068978Z",
     "start_time": "2021-08-23T07:15:20.064783Z"
    }
   },
   "source": [
    "#### step 5. latent vector `z`를 (모든) input data에 concatenate\n",
    "\n",
    "* 매 token 마다 latent vector의 정보를 추가하여 성능을 높이기 위해서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:54:48.409134Z",
     "start_time": "2021-08-29T06:54:48.406063Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.cat((x, z_), dim=-1)  # x: [batch_size, 1, embedding_dim + latent_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 6. concatenate한 input 데이터 gru에 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:54:48.586256Z",
     "start_time": "2021-08-29T06:54:48.582580Z"
    }
   },
   "outputs": [],
   "source": [
    "x, hiddens = model.decoder.gru(x, hiddens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T07:30:43.052727Z",
     "start_time": "2021-08-23T07:30:43.050241Z"
    }
   },
   "source": [
    "#### step 7. `outputs`을 `Linear`레이어를 통과시켜서 `next_token_logits`을 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:54:48.715381Z",
     "start_time": "2021-08-29T06:54:48.711926Z"
    }
   },
   "outputs": [],
   "source": [
    "logits = model.decoder.fc(x)\n",
    "next_token_logits = logits.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:54:48.828400Z",
     "start_time": "2021-08-29T06:54:48.823866Z"
    }
   },
   "outputs": [],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:54:48.941823Z",
     "start_time": "2021-08-29T06:54:48.938007Z"
    }
   },
   "outputs": [],
   "source": [
    "next_token_logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T01:52:29.148625Z",
     "start_time": "2021-08-20T01:52:29.145709Z"
    }
   },
   "source": [
    "#### step 8. `next_token_logits`을 `softmax`를 통해 확률분포를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:54:49.088286Z",
     "start_time": "2021-08-29T06:54:49.085269Z"
    }
   },
   "outputs": [],
   "source": [
    "probabilities = F.softmax(next_token_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:54:49.224601Z",
     "start_time": "2021-08-29T06:54:49.217815Z"
    }
   },
   "outputs": [],
   "source": [
    "probabilities[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T01:52:29.586382Z",
     "start_time": "2021-08-20T01:52:29.581315Z"
    }
   },
   "source": [
    "#### step 9. 이 확률분포를 기반한 sampling 작업을 함 ([`torch.multinomial`](https://pytorch.org/docs/stable/generated/torch.multinomial.html?highlight=multinomial#torch.multinomial)을 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:54:49.393532Z",
     "start_time": "2021-08-29T06:54:49.389035Z"
    }
   },
   "outputs": [],
   "source": [
    "next_tokens = torch.multinomial(probabilities, num_samples=1)\n",
    "next_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T01:49:41.633366Z",
     "start_time": "2021-08-20T01:49:41.626309Z"
    }
   },
   "source": [
    "참고 `tokenizer.vocab`\n",
    "\n",
    "```python\n",
    "{('#', 4), ('(', 5), (')', 6), ('-', 7),\n",
    " ('1', 8), ('2', 9), ('3', 10), ('4', 11), ('5', 12), ('6', 13), ('=', 14),\n",
    " ('B', 15), ('C', 16), ('F', 17), ('H', 18), ('N', 19), ('O', 20), ('S', 21),\n",
    " ('[', 22), (']', 23), ('c', 24), ('l', 25), ('n', 26), ('o', 27), ('r', 28), ('s', 29)}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T07:36:08.564746Z",
     "start_time": "2021-08-23T07:36:08.561366Z"
    }
   },
   "source": [
    "#### step 10. 실제로 sampling된 값이 `next_tokens`이 되고 이게 다음 스텝의 rnn 인풋으로 쓰임 (`input_ids = next_tokens`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T06:54:50.428873Z",
     "start_time": "2021-08-29T06:54:50.423107Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs_ids = next_tokens\n",
    "generated_sequences = torch.cat((generated_sequences, next_tokens), dim=1)\n",
    "generated_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-20T02:04:21.601326Z",
     "start_time": "2021-08-20T02:04:21.598478Z"
    }
   },
   "source": [
    "#### 위의 과정을 모듈화해서 `generate`함수를 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:25:28.091943Z",
     "start_time": "2021-08-30T11:25:27.300894Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model.generate(tokenizer=tokenizer,\n",
    "                         max_length=128,\n",
    "                         #num_return_sequences=batch_size_for_generate,\n",
    "                         num_return_sequences=256,\n",
    "                         skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:25:30.616760Z",
     "start_time": "2021-08-30T11:25:30.551156Z"
    }
   },
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:25:30.895446Z",
     "start_time": "2021-08-30T11:25:30.861309Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mols = []\n",
    "for s in outputs:\n",
    "  try:\n",
    "    mol = Chem.MolFromSmiles(s)\n",
    "  except:\n",
    "    pass\n",
    "  if mol is not None:\n",
    "    mols.append(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:25:32.395763Z",
     "start_time": "2021-08-30T11:25:32.390583Z"
    }
   },
   "outputs": [],
   "source": [
    "len(mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:25:34.898035Z",
     "start_time": "2021-08-30T11:25:34.886078Z"
    }
   },
   "outputs": [],
   "source": [
    "mols[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:25:35.124092Z",
     "start_time": "2021-08-30T11:25:35.111159Z"
    }
   },
   "outputs": [],
   "source": [
    "mols[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T11:25:35.428932Z",
     "start_time": "2021-08-30T11:25:35.416465Z"
    }
   },
   "outputs": [],
   "source": [
    "mols[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:laiddmg] *",
   "language": "python",
   "name": "conda-env-laiddmg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
